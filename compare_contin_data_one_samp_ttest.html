<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>One sample Student’s t-test - Romeo and Julia</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia</a>
</div><br />
<span class="books-subtitle">
where Romeo is Basic Statistics
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>6</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="5.2" id="sec:compare_contin_data_one_samp_ttest"><span class="header-section-number">5.2</span> One sample Student’s t-test</h2>
<p>Imagine that in your town there is a small local brewery that produces quite expensive but super tasty beer. You like it a lot, but you got an impression that the producer is not being honest with their customers and instead of the declared 500 [mL] of beer per bottle, he pours a bit less. Still, there is little you can do to prove it. Or can you?</p>
<p>You bought 10 bottles of beer (ouch, that was expensive!) and measured the volume of fluid in each of them. The results are as follows</p>
<pre class="language-julia"><code># a representative sample
beerVolumes = [504, 477, 484, 476, 519, 481, 453, 485, 487, 501]</code></pre>
<p>On a graph the volume distribution looks like this (it was drawn with <a href="https://docs.makie.org/stable/examples/plotting_functions/hist/index.html#hist">Cmk.hist</a> function).</p>
<figure>
<img src="./images/histBeerVolume.png" id="fig:histBeerVolume" alt="Figure 12: Histogram of beer volume distribution for 10 beer." /><figcaption aria-hidden="true">Figure 12: Histogram of beer volume distribution for 10 beer.</figcaption>
</figure>
<p>You look at it and it seems to resemble a bit the bell shaped curve that we discussed in the Section <a href="./statistics_normal_distribution.html#sec:statistics_normal_distribution">4.6</a>. This makes sense. Imagine your task is to pour let’s say 1’000 bottles daily with 500 [mL] of beer in each with a big mug. Most likely the volumes would oscillate around your goal volume of 500 [mL], but they would not be exact. Sometimes in a hurry you would add a bit more, sometimes a bit less (you could not waste time to correct it). So it seems like a reasonable assumption that the 1’000 bottles from our example would have a roughly bell shaped (aka normal) distribution of volumes around the mean.</p>
<p>Now you can calculate the mean and standard deviation for the data</p>
<pre class="language-julia"><code>import Statistics as Stats

meanBeerVol = Stats.mean(beerVolumes)
stdBeerVol = Stats.std(beerVolumes)

(meanBeerVol, stdBeerVol)</code></pre>
<pre class="output"><code>(486.7, 18.055777776410274)</code></pre>
<p>Hmm, on average there was 486.7 [mL] of beer per bottle, but the spread of the data around the mean is also considerable (sd = 18.06 [mL]). The lowest value measured was 453 [mL], the highest value measured was 519 [mL]. Still, it seems that there is less beer per bottle than expected but is it enough to draw a conclusion that the real mean in the population of our 1’000 bottles is ≈ 487.0 [mL] and not 500 [mL] as it should be? Let’s try to test that using what we already know about the normal distribution (see Section <a href="./statistics_normal_distribution.html#sec:statistics_normal_distribution">4.6</a>), the three sigma rule (Section <a href="./statistics_normal_distribution.html#sec:statistics_intro_three_sigma_rule">4.6.1</a>) and the <code>Distributions</code> package (Section <a href="./statistics_normal_distribution.html#sec:statistics_intro_distributions_package">4.6.2</a>).</p>
<p>Let’s assume for a moment that the true mean for volume of fluid in the population of 1’000 beer bottles is <code>meanBeerVol</code> = 486.7 [mL] and the true standard deviation is <code>stdBeerVol</code> = 18.06 [mL]. That would be great because now, based on what we’ve learned in Section <a href="./statistics_normal_distribution.html#sec:statistics_intro_distributions_package">4.6.2</a> we can calculate the probability that a random bottle of beer got &gt;500 [mL] of fluid (or % of beer bottles in the population that contain &gt;500 [mL] of fluid). Let’s do it</p>
<pre class="language-julia"><code>import Distributions as Dsts

# how many std. devs is value above or below the mean
function getZScore(mean::Real, sd::Real, value::Real)::Float64
    return (value - mean)/sd
end

expectedBeerVolmL = 500

fractionBeerLessEq500mL = Dsts.cdf(Dsts.Normal(),
    getZScore(meanBeerVol, stdBeerVol, expectedBeerVolmL))
fractionBeerAbove500mL = 1 - fractionBeerLessEq500mL

fractionBeerAbove500mL</code></pre>
<p>0.2306808956300721</p>
<p>I’m not going to explain the code above since for reference you can always check Section <a href="./statistics_normal_distribution.html#sec:statistics_intro_distributions_package">4.6.2</a>. Still, under those assumptions roughly 0.23 or 23% of beer bottles contain more than 500 [mL] of fluid. In other words under these assumptions the probability that a random beer bottle contains &gt;500 [mL] of fluid is 0.23 or 23%.</p>
<p>There are 2 problems with that solution.</p>
<p><strong>Problem 1</strong></p>
<p>It is true that the mean from the sample is our best estimate of the mean in the population (here 1’000 beer bottles poured daily). However, statisticians proved that instead of the standard deviation from our sample we should use the <a href="https://en.wikipedia.org/wiki/Standard_error">standard error of the mean</a>. It describes the spread of sample means around the true population mean and it can be calculated as follows</p>
<p><span class="math inline">\(sem = \frac{sd}{\sqrt{n}}\)</span>, where</p>
<p>sem - standard error of the mean</p>
<p>sd - standard deviation</p>
<p>n - number of observations in the sample</p>
<p><br />
Let’s enclose it into Julia code</p>
<pre class="language-julia"><code>function getSem(vect::Vector{&lt;:Real})::Float64
    return Stats.std(vect) / sqrt(length(vect))
end</code></pre>
<p>Now we get a better estimate of the probability</p>
<pre class="language-julia"><code>fractionBeerLessEq500mL = Dsts.cdf(Dsts.Normal(),
    getZScore(meanBeerVol, getSem(beerVolumes), expectedBeerVolmL))
fractionBeerAbove500mL = 1 - fractionBeerLessEq500mL

fractionBeerAbove500mL</code></pre>
<p>0.00992016769999493</p>
<p>Under those assumptions the probability that a beer bottle contains &gt;500 [mL] of fluid is roughly 0.01 or 1%.</p>
<p>So, to sum up. Here, we assumed that the true mean in the population is our sample mean (<span class="math inline">\(\mu\)</span> = <code>meanBeerVol</code>). Next, if we were to take many small samples like <code>beerVolumes</code> and calculate their means then they would be normally distributed around the population mean (here <span class="math inline">\(\mu\)</span> = <code>meanBeerVol</code>) with <span class="math inline">\(\sigma\)</span> (standard deviation in the population) = <code>getSem(beerVolumes)</code>. Finally, using the three sigma rule (see Section <a href="./statistics_normal_distribution.html#sec:statistics_intro_three_sigma_rule">4.6.1</a>) we check if our hypothesized mean (<code>expectedBeerVolmL</code>) lies within roughly 2 standard deviations (here approximately 2 <code>sem</code>s) from the assumed population mean (here <span class="math inline">\(\mu\)</span> = <code>meanBeerVol</code>).</p>
<p><strong>Problem 2</strong></p>
<p>The sample size is small (<code>length(beerVolumes)</code> = 10) so the underlying distribution is quasi-normal. It is called a <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">t-distribution</a> (for comparison of an exemplary normal and t-distribution see the figure below). Therefore to get a better estimate of the probability we should use the distribution.</p>
<figure>
<img src="./images/normDistTDist.png" id="fig:normDistTDist" alt="Figure 13: Comparison of normal and t-distribution with 4 degrees of freedom (df = 4)." /><figcaption aria-hidden="true">Figure 13: Comparison of normal and t-distribution with 4 degrees of freedom (df = 4).</figcaption>
</figure>
<p>Luckily our <code>Distributions</code> package got the t-distribution included (see <a href="https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.TDist">the docs</a>). As you remember the normal distribution required two parameters that described it: the mean and the standard deviation. The t-distribution requires <a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">degrees of freedom</a>. The concept is fairly easy to understand. Imagine that we recorded body masses of 3 people in the room: Paul, Peter, and John.</p>
<pre class="language-julia"><code>peopleBodyMassesKg = [84, 94, 78]

sum(peopleBodyMassesKg)</code></pre>
<p>256</p>
<p>As you can see the sum of those body masses is 256 [kg]. Notice however that only two of those masses are independent or free to change. Once we know any two of the body masses (e.g. 94, 78) and the sum: 256, then the third body mass must be equal to <code>sum(peopleBodyMassesKg) - 94 - 78</code> = 84 (it is determined, it cannot just freely take any value). So in order to calculate the degrees of freedom we type <code>length(peopleBodyMassesKg) - 1</code> = 2. Since our sample size is equal to <code>length(beerVolumes)</code> = 10 then it will follow a t-distribution with <code>length(beerVolumes) - 1</code> = 9 degrees of freedom.</p>
<p>So the probability that a beer bottle contains &gt;500 [mL] of fluid is</p>
<pre class="language-julia"><code>function getDf(vect::Vector{&lt;:Real})::Int
    return length(vect) - 1
end

fractionBeerLessEq500mL = Dsts.cdf(Dsts.TDist(getDf(beerVolumes)),
    getZScore(meanBeerVol, getSem(beerVolumes), expectedBeerVolmL))
fractionBeerAbove500mL = 1 - fractionBeerLessEq500mL

fractionBeerAbove500mL</code></pre>
<p>0.022397253591088795</p>
<blockquote>
<p><strong><em>Note:</em></strong> The z-score (number of standard deviations above the mean) for a t-distribution is called t-score or t-statistics (it is calculated with sem instead of sd).</p>
</blockquote>
<p>Finally, we got the result. Based on our representative sample (<code>beerVolumes</code>) and the assumptions we made we can see that the probability that a random beer contains &gt;500 [mL] of fluid (500 [mL] is stated on a label) is <code>fractionBeerAbove500mL</code> = 0.022 or 2.2% (remember, this is one-tailed probability, the two-tailed probability is 0.022 * 2 = 0.044 = 4.4%).</p>
<p>Given that the cutoff level for <span class="math inline">\(\alpha\)</span> (type I error) from Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_errors">4.7.5</a> is 0.05 we can reject our <span class="math inline">\(H_{0}\)</span> (the assumption that 500 [mL] comes from the population with the mean approximated by <span class="math inline">\(\mu\)</span> = <code>meanBeerVol</code> = 486.7 [mL] and the standard deviation approximated by <span class="math inline">\(\sigma\)</span> = <code>sem</code> = 5.71 [mL]).</p>
<p>In conclusion, our hunch was right (“…you got an impression that the producer is not being honest with their customers…”). The owner of the local brewery is dishonest and intentionally pours slightly less beer (on average <code>expectedBeerVolmL - meanBeerVol</code> = 13.0 [mL]). Now we can go to him and get our money back, or alarm the proper authorities for that monstrous crime. <em>Fun fact: the story has it that the <a href="https://en.wikipedia.org/wiki/Code_of_Hammurabi">code of Hammurabi</a> (circa 1750 BC) was the first to punish for diluting a beer with water (although it seems to be more of a legend).</em> Still, this is like 2-3% beer (≈13/500 = 0.026) in a bottle less than it should be and the two-tailed probability (<code>fractionBeerAbove500mL * 2</code> = 0.045) is not much less than the cutoff for type 1 error equal to 0.05 (we may want to collect a bigger sample and change the cutoff to 0.01).</p>
<h3 data-number="5.2.1" id="sec:compare_contin_data_hypo_tests_package"><span class="header-section-number">5.2.1</span> HypothesisTests package</h3>
<p>The above paragraphs were to further your understanding of the topic. In practice you can do this much faster using <a href="https://juliastats.org/HypothesisTests.jl/stable/">HypothesisTests</a> package.</p>
<p>In our beer example you could go with this short snippet (see <a href="https://juliastats.org/HypothesisTests.jl/stable/parametric/#t-test">the docs</a> for <code>Htests.OneSampleTTest</code>)</p>
<pre class="language-julia"><code>import HypothesisTests as Htests

Htests.OneSampleTTest(beerVolumes, expectedBeerVolmL)</code></pre>
<pre class="output"><code>One sample t-test
-----------------
Population details:
    parameter of interest:   Mean
    value under h_0:         500
    point estimate:          486.7
    95% confidence interval: (473.8, 499.6)

Test summary:
    outcome with 95% confidence: reject h_0
    two-sided p-value:           0.0448

Details:
    number of observations:   10
    t-statistic:              -2.329353706113303
    degrees of freedom:       9
    empirical standard error: 5.70973826993069
</code></pre>
<p>Let’s compare it with our previous results</p>
<pre class="language-julia"><code>(
expectedBeerVolmL, # value under h_0
meanBeerVol, # point estimate
fractionBeerAbove500mL * 2, # two-sided p-value
getZScore(meanBeerVol, getSem(beerVolumes), expectedBeerVolmL), # t-statistic
getDf(beerVolumes), # degrees of freedom
getSem(beerVolumes) # empirical standard error
)</code></pre>
<pre class="output"><code>(500, 486.7, 0.04479450718217759, 2.329353706113303, 9, 5.70973826993069)</code></pre>
<p>The numbers are pretty much the same (and they should be if the previous explanation was right). The t-statistic is positive in our case because <code>getZScore</code> subtracts <code>mean</code> from <code>value</code> (<code>value - mean</code>) and some packages (like <code>HypothesisTests</code>) swap the numbers.</p>
<p>The value that needs to be additionally explained is the <a href="https://en.wikipedia.org/wiki/Confidence_interval">95% confidence interval</a> from the output of <code>HypothesisTests</code> above. All it means is that: if we were to run our experiment with 10 beers 100 times and calculate 95% confidence intervals 100 times then 95 of the intervals would contained the true mean from the population. Sometimes people simplify it and say that this interval [in our case (473.8, 499.6)] contains the true mean from the population with probability of 95% (but that isn’t necessarily the same what was stated in the previous sentence). The narrower interval means better, more precise estimate. If the difference is statistically significant (p-value &lt; 0.05) then the interval should not contain the postulated mean (as in our case).</p>
<p>Notice that in our case the obtained 95% interval (473.8, 499.6) may indicate that the true average volume of fluid in a bottle of beer could be as high as 499.6 [mL] (so this would hardly make a practical difference) or as low as 473.8 [mL] (a small, ~6%, but a practical difference). In the case of our beer example it is just a curious fact, but imagine you are testing a new drug lowering the ‘bad cholesterol’ (LDL-C) level (the one that was mentioned in Section <a href="./statistics_intro_exercises_solutions.html#sec:statistics_intro_exercise5_solution">4.9.5</a>). Let’s say you got a 95% confidence interval for the reduction of (-132, +2). The interval encompasses 0, so the true effect may be 0 and you cannot reject <span class="math inline">\(H_{0}\)</span> under those assumptions (p-value would be &gt; 0.05). However, the interval is broad, and its lower value is -132, which means that the true reduction level after applying this drug could be even -132 [mg/dL]. Based on the data from <a href="https://en.wikipedia.org/wiki/Low-density_lipoprotein#Normal_ranges">this table</a> I guess this could have a big therapeutic meaning. So, you might want to consider performing another experiment on the effects of the drug, but this time you should take a bigger sample to dispel the doubt (bigger samples size narrows the 95% confidence interval).</p>
<p>In general one sample t-test is used to check if a sample comes from a population with the postulated mean (in our case in <span class="math inline">\(H_{0}\)</span> the postulated mean was 500 [mL]). However, I prefer to look at it from the different perspective (the other end) hence my explanation above. The t-test is named after <a href="https://en.wikipedia.org/wiki/William_Sealy_Gosset">William Sealy Gosset</a> that published his papers under the pen-name Student, hence it is also called a Student’s t-test.</p>
<h3 data-number="5.2.2" id="sec:compare_contin_data_check_assump"><span class="header-section-number">5.2.2</span> Checking the assumptions</h3>
<p>Hopefully, the explanations above were clear enough. Still, we shouldn’t just jump into performing a test blindly, first we should test its assumptions (see figure below).</p>
<figure>
<img src="./images/testAssumptionsCheckCycle.png" id="fig:testAssumptionsCheckCycle" alt="Figure 14: Checking assumptions of a statistical test before running it." /><figcaption aria-hidden="true">Figure 14: Checking assumptions of a statistical test before running it.</figcaption>
</figure>
<p>First of all we start by choosing a test to perform. Usually it is a <a href="https://en.wikipedia.org/wiki/Parametric_statistics">parametric test</a>, i.e. one that assumes some specific data distribution (e.g. normal). Then we check our assumptions. If they hold we proceed with our test. Otherwise we can either transform the data (e.g. take a logarithm from each value) or choose a different test (the one that got different assumptions or just less of them to fulfill). This different test usually belongs to so called <a href="https://en.wikipedia.org/wiki/Nonparametric_statistics">non-parametric tests</a>, i.e. tests that make less assumptions about the data, but are likely to be slightly less powerful (you remember power of a test from Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_errors">4.7.5</a>, right?).</p>
<p>In our case a Student’s t-test requires data to be normally distributed. This is usually verified with <a href="https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test">Shapiro-Wilk test</a> or <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov-Smirnov test</a>. As an alternative to Student’s t-test (when the normality assumption does not hold) a <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">Wilcoxon test</a> is often performed (of course before you use it you should check its assumptions, see Figure <a href="#fig:testAssumptionsCheckCycle">14</a> above).</p>
<p>Both Kolmogorov-Smirnov (see <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Kolmogorov-Smirnov-test">this docs</a>) and Wilcoxon test (see <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Wilcoxon-signed-rank-test">that docs</a>) are at our disposal in <code>HypothesisTests</code> package. Behold</p>
<pre class="language-julia"><code>Htests.ExactOneSampleKSTest(beerVolumes,
    Dsts.Normal(meanBeerVol, stdBeerVol))</code></pre>
<pre class="output"><code>Exact one sample Kolmogorov-Smirnov test
----------------------------------------
Population details:
    parameter of interest:   Supremum of CDF differences
    value under h_0:         0.0
    point estimate:          0.193372

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.7826

Details:
    number of observations:   10
</code></pre>
<p>So it seems we got no grounds to reject the <span class="math inline">\(H_{0}\)</span> that states that our data are normally distributed (p-value &gt; 0.05) and we were right to perform our one-sample Student’s t-test. Of course, I had checked the assumptions before I conducted the test. I didn’t mention it there because I didn’t want to prolong my explanation (and diverge from the topic) back there.</p>
<p>And now a question. Is the boring assumption check before a statistical test really necessary?</p>
<p>Well, only if you want your conclusions to reflect the reality.</p>
<p>So, yes. Even though a statistical textbook for brevity may not check the assumptions of a method you should always do it in your analyses if your care about the correctness of your judgment.</p>
<p>To be continued…</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>