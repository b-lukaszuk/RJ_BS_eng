<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Solutions - Comparisons of Continuous Data - Romeo and Julia, where Romeo is Basic Statistics</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia, where Romeo is Basic Statistics</a>
</div><br />
<span class="books-subtitle">

</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises_solutions.html"><b>5.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_imports.html"><b>6.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_flashback.html"><b>6.2</b> Flashback</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_chisq_test.html"><b>6.3</b> Chi squared test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_fisher_exact_text.html"><b>6.4</b> Fisher’s exact test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_bigger_table.html"><b>6.5</b> Bigger table</a></li>
<li><a class="menu-level-2" href="./compare_categ_test_for_independence.html"><b>6.6</b> Test for independence</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises.html"><b>6.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises_solutions.html"><b>6.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>7</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="5.8" id="sec:compare_contin_data_exercises_solutions"><span class="header-section-number">5.8</span> Solutions - Comparisons of Continuous Data</h2>
<p>In this sub-chapter you will find exemplary solutions to the exercises from the previous section.</p>
<h3 data-number="5.8.1" id="sec:compare_contin_data_ex1_solution"><span class="header-section-number">5.8.1</span> Solution to Exercise 1</h3>
<p>First the sample and the 100’000 simulations:</p>
<pre class="language-julia"><code>Rand.seed!(321)
ex1sample = Rand.rand(Dsts.Normal(80, 20), 10)
ex1sampleSd = Stats.std(ex1sample)
ex1sampleSem = getSem(ex1sample)
ex1sampleMeans = [
    Stats.mean(Rand.rand(Dsts.Normal(80, 20), 10))
    for _ in 1:100_000]
ex1sampleMeansMean = Stats.mean(ex1sampleMeans)
ex1sampleMeansSd = Stats.std(ex1sampleMeans)</code></pre>
<p>The code doesn’t contain any new elements, so I will leave it to you to figure out what happened in the code snippet above.</p>
<p>And now, let’s move to the plot.</p>
<pre class="language-julia"><code>fig = Cmk.Figure()
Cmk.hist(fig[1, 1], ex1sampleMeans, bins=100, color=Cmk.RGBAf(0, 0, 1, 0.3),
    axis=(;
        title=&quot;Histogram of 100&#39;000 sample means&quot;,
        xlabel=&quot;Adult human body weight [kg]&quot;,
        ylabel=&quot;Count&quot;))
Cmk.ylims!(0, 4000)
Cmk.vlines!(fig[1, 1], 80,
    ymin=0.0, ymax=0.85, color=&quot;black&quot;, linestyle=:dashdot)
Cmk.text!(fig[1, 1], 81, 1000, text=&quot;population mean = 80&quot;)
Cmk.bracket!(fig[1, 1],
    ex1sampleMeansMean - ex1sampleMeansSd / 2, 3500,
    ex1sampleMeansMean + ex1sampleMeansSd / 2, 3500,
    style=:square
)
Cmk.text!(fig[1, 1], 72.5, 3700,
    text=&quot;sample means sd = 6.33&quot;)
Cmk.text!(fig[1, 1], 90, 3200,
    text=&quot;single sample sd = 17.32&quot;)
Cmk.text!(fig[1, 1], 90, 3000,
    text=&quot;single sample sem = 5.48&quot;)
fig</code></pre>
<p>This produces the following graph.</p>
<figure>
<img src="./images/histCh05Ex1.png" id="fig:histCh05Ex1" alt="Figure 18: Histogram of drawing 100’000 random samples from a population with \mu = 80 and \sigma = 20." /><figcaption aria-hidden="true">Figure 18: Histogram of drawing 100’000 random samples from a population with <span class="math inline">\(\mu = 80\)</span> and <span class="math inline">\(\sigma = 20\)</span>.</figcaption>
</figure>
<p>The graph clearly demonstrates that a better approximation of the samples means sd is <code>sem</code> and not <code>sd</code> (as stated in Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a>).</p>
<p>I’m not gonna explain the code snippet above in great detail since this is a warm up exercise, and <a href="https://docs.makie.org/stable/tutorials/">the tutorials</a> (e.g. the basic tutorial) and the documentation for the plotting functions (see the links in Section <a href="./compare_contin_data_exercises.html#sec:compare_contin_data_ex1">5.7.1</a>) are pretty good. Moreover, we already used <code>CairoMakie</code> plotting functions in Section <a href="./statistics_prob_distribution.html#sec:statistics_prob_distribution">4.5</a>. Still, a few quick notes are in order.</p>
<p>First of all, drawing a graph like that is not an enormous feat, you just need some knowledge (you read the tutorial and the function docs, right?). The rest is just patience and replication of the examples. Ah yes, I forgot about try and error [that happens from time to time (OK, more often than I would like to admit) in my case]. If an error happens, do not panic try to read the error’s message and think what it tells you).</p>
<p>It is always a good idea to annotate the graph, add the title, x- and y-axis labels (to make the reader’s, and your own, reasoning easier). Figures are developed from top to bottom (in the code), layer after layer (top line of code -&gt; bottom layer, next line of code places a layer above the previous layer). First function (<code>fig</code> and <code>Cmk.hist</code>) creates the figure, the following functions (e.g. <code>Cmk.text!</code> and <code>Cmk.vlines</code>), write/paint something on the previous layers. After some time and tweaking you should be able to produce quite pleasing figures (just remember, patience is the key). One more point, instead of typing strings by hand (like <code>text="sample sd = 17.32"</code>) you may let Julia do that by using <a href="https://docs.julialang.org/en/v1/manual/strings/#string-interpolation">strings interpolation</a>, like <code>text="sample sd = $(round(ex1sampleSd, digits=2))"</code>(with time you will appreciate the convenience of this method).</p>
<h3 data-number="5.8.2" id="sec:compare_contin_data_ex2_solution"><span class="header-section-number">5.8.2</span> Solution to Exercise 2</h3>
<p>First let’s start with the functions we developed in Section <a href="./statistics_intro.html#sec:statistics_intro">4</a> (and its subsections). We already now them, so I will not explain them here.</p>
<pre class="language-julia"><code>function getCounts(v::Vector{T})::Dict{T,Int} where {T}
    counts::Dict{T,Int} = Dict()
    for elt in v
        counts[elt] = get(counts, elt, 0) + 1
    end
    return counts
end

function getProbs(counts::Dict{T,Int})::Dict{T,Float64} where {T}
    total::Int = sum(values(counts))
    return Dict(k =&gt; v / total for (k, v) in counts)
end

function getSortedKeysVals(d::Dict{T1,T2})::Tuple{
    Vector{T1},Vector{T2}} where {T1,T2}

    sortedKeys::Vector{T1} = keys(d) |&gt; collect |&gt; sort
    sortedVals::Vector{T2} = [d[k] for k in sortedKeys]
    return (sortedKeys, sortedVals)
end</code></pre>
<p>Now, time to define <code>getLstatistic</code> based on what we learned in Section <a href="./compare_contin_data_one_way_anova.html#sec:compare_contin_data_one_way_anova">5.4</a> (note, the function uses <code>getAbsGroupDiffsAroundOverallMean</code> and <code>getAbsPointDiffsFromGroupMeans</code> that we developed in that section).</p>
<pre class="language-julia"><code>function getLStatistic(v1::Vector{&lt;:Real}, v2::Vector{&lt;:Real})::Float64
    absDiffsOverallMean::Vector{&lt;:Real} =
        getAbsGroupDiffsFromOverallMean(v1, v2)
    absDiffsGroupMean::Vector{&lt;:Real} =
        getAbsPointDiffsFromGroupMeans(v1, v2)
    return Stats.mean(absDiffsOverallMean) / Stats.mean(absDiffsGroupMean)
end</code></pre>
<p>OK, that was easy, after all we practically did it all before, we only needed to look for it in the previous chapters. Now, the function to determine the distribution.</p>
<pre class="language-julia"><code>function getLStatisticsUnderH0(
    popMean::Real, popSd::Real,
    nPerGroup::Int=4, nIter::Int=1_000_000)::Vector{Float64}

    v1::Vector{Float64} = []
    v2::Vector{Float64} = []
    result::Vector{Float64} = zeros(nIter)

    for i in 1:nIter
        v1 = Rand.rand(Dsts.Normal(popMean, popSd), nPerGroup)
        v2 = Rand.rand(Dsts.Normal(popMean, popSd), nPerGroup)
        result[i] = getLStatistic(v1, v2)
    end

    return result
end</code></pre>
<p>This one is slightly more complicated so I think a bit of explanation is in order here. First we initialize some variables that we will use later. For instance, <code>v1</code> and <code>v2</code> will hold random samples drawn from a population of interest (<code>Dsts.Normal(popMean, popSd)</code>) and will change with each iteration. The vector <code>result</code> is initialized with <code>0</code>s and will hold the <code>LStatistic</code> calculated during each iteration for <code>v1</code> and <code>v2</code>. The result vector is returned by the function. Later on we will be able to use it to <code>getCounts</code> and <code>getProbs</code> for the L-Statistics. This should work just fine. However, if we slightly modify our function (<code>getLStatisticsUnderH0</code>), we could use it not only with the L-Statistic but also F-Statistic (optional points in this task) or any other statistic of interest. Observe</p>
<pre class="language-julia"><code># getXStatFn signature: fnName(::Vector{&lt;:Real}, ::Vector{&lt;:Real})::Float64
function getXStatisticsUnderH0(
    getXStatFn::Function,
    popMean::Real, popSd::Real,
    nPerGroup::Int=4, nIter::Int=1_000_000)::Vector{Float64}

    v1::Vector{Float64} = []
    v2::Vector{Float64} = []
    result::Vector{Float64} = zeros(nIter)

    for i in 1:nIter
        v1 = Rand.rand(Dsts.Normal(popMean, popSd), nPerGroup)
        v2 = Rand.rand(Dsts.Normal(popMean, popSd), nPerGroup)
        result[i] = getXStatFn(v1, v2)
    end

    return result
end</code></pre>
<p>Here, instead of <code>getLStatisticsUnderH0</code> we named the function <code>getXStatisticsUnderH0</code>, where <code>X</code> is any statistic we can come up with. The function that calculates our statistic of interest is passed as a first argument to <code>getXStatisticsUnderH0</code> (<code>getXStatFn</code>). The <code>getXStatFn</code> should work just fine, if it accepts two vectors (<code>::Vector{&lt;:Real}</code>) and returns <code>Float64</code> (the statistic) of interest. Both those assumptions are fulfilled by <code>getLStatistic</code> (defined above) and <code>getFStatistic</code> defined in Section <a href="./compare_contin_data_one_way_anova.html#sec:compare_contin_data_one_way_anova">5.4</a>. To use our <code>getXStatisticsUnderH0</code> we would type, e.g.: <code>getXStatisticsUnderH0(getLStatistic, 25, 3, 4)</code> instead of <code>getLStatisticsUnderH0(25, 3, 4)</code> that we would have used for <code>getLStatisticsUnderH0</code> defined above (more typing, but greater flexibility, and the result would be the same).</p>
<p>Now, to get a distribution of interest we use the following function</p>
<pre class="language-julia"><code># getXStatFn signature: fnName(::Vector{&lt;:Real}, ::Vector{&lt;:Real})::Float64
function getXDistUnderH0(getXStatFn::Function,
    mean::Real, sd::Real,
    nPerGroup::Int=4, nIter::Int=10^6)::Dict{Float64,Float64}

    xStats::Vector{&lt;:Float64} = getXStatisticsUnderH0(
        getXStatFn, mean, sd, nPerGroup, nIter)
    xStats = round.(xStats, digits=1)
    xCounts::Dict{Float64,Int} = getCounts(xStats)
    xProbs::Dict{Float64,Float64} = getProbs(xCounts)

    return xProbs
end</code></pre>
<p>First, we calculate the statistics of interest (<code>xStats</code>), then we round the statistics to a 1 decimal point (<code>round.(xStats, digits=1)</code>). This is necessary, since in a moment we will use <code>getCounts</code> so we need some repetitions in our <code>xStats</code> vector (e.g. 1.283333331 and 1.283333332 will, both get rounded to 1.3 and the count for this value of the statistic will be 2). Once we got the counts, we change them to probabilities (fraction of times that the given value of the statistic occurred) with <code>getProbs</code>.</p>
<p>Now we can finally, use them to estimate the probability that the L-statistic greater than <code>LStatisticEx2</code> = 1.28 occurred by chance.</p>
<pre class="language-julia"><code>Rand.seed!(321)
lprobs = getXDistUnderH0(getLStatistic, 25, 3)
lprobsGTLStatisticEx2 = [v for (k, v) in lprobs if k &gt; LStatisticEx2]
lStatProb = sum(lprobsGTLStatisticEx2)</code></pre>
<p>0.045378999999999996</p>
<p>The estimated probability for our L-Statistic is 0.045 which is pretty close to the probability obtained for the F-Statistic (<code>Htests.OneWayANOVATest(ex2BwtsWater, ex2BwtsDrugY) |&gt; Htests.pvalue</code> = 0.043) (and well it should).</p>
<p>In virtually the same way we can get the experimental probability of an F-statistic being greater than <code>getFStatistic(ex2BwtsWater, ex2BwtsDrugY)</code> = 6.56 by chance. Observe</p>
<pre class="language-julia"><code>Rand.seed!(321)
cutoffFStat = getFStatistic(ex2BwtsWater, ex2BwtsDrugY)
fprobs = getXDistUnderH0(getFStatistic, 25, 3)
fprobsGTCutoffFStat = [v for (k, v) in fprobs if k &gt; cutoffFStat]
fStatProb = sum(fprobsGTCutoffFStat)</code></pre>
<p>0.043154000000000005</p>
<p>Again, the p-value is quite similar to the one we got from a formal <code>Htests.OneWayANOVATest</code> (as it should be).</p>
<p>OK, now it’s time to draw some plots. First, let’s get the values for x- and y-axes</p>
<pre class="language-julia"><code>Rand.seed!(321)
# L distributions
lxs1, lys1 = getXDistUnderH0(getLStatistic, 25, 3) |&gt; getSortedKeysVals
lxs2, lys2 = getXDistUnderH0(getLStatistic, 100, 50) |&gt; getSortedKeysVals
lxs3, lys3 = getXDistUnderH0(getLStatistic, 25, 3, 8) |&gt; getSortedKeysVals
# F distribution
fxs1, fys1 = getXDistUnderH0(getFStatistic, 25, 3) |&gt; getSortedKeysVals</code></pre>
<p>No, big deal L-Distributions start with <code>l</code>, the classical F-Distribution starts with <code>f</code>. BTW. Notice that thanks to <code>getXDistUnderH0</code> we didn’t have to write two almost identical functions (<code>getLDistUnderH0</code> and <code>getFDistUnderH0</code>).</p>
<p>OK, let’s place them on the graph</p>
<pre class="language-julia"><code>fig = Cmk.Figure()
ax1, l1 = Cmk.lines(fig[1, 1], fxs1, fys1, color=&quot;red&quot;,
    axis=(;
        title=&quot;F-Distribution (red) and L-Distribution (blue)&quot;,
        xlabel=&quot;Value of the statistic&quot;,
        ylabel=&quot;Probability distribution&quot;))
l2 = Cmk.lines!(fig[1, 1], lxs1, lys1, color=&quot;blue&quot;)
sc1 = Cmk.scatter!(fig[1, 1], lxs2, lys2, color=&quot;blue&quot;, marker=:circle)
sc2 = Cmk.scatter!(fig[1, 1], lxs3, lys3, color=&quot;blue&quot;, marker=:xcross)
Cmk.vlines!(fig[1, 1], LStatisticEx2, color=&quot;lightblue&quot;, type=:dashdot)
Cmk.text!(fig[1, 1], 1.35, 0.1,
    text=&quot;L-Statistic = 1.28&quot;)
Cmk.xlims!(0, 4)
Cmk.ylims!(0, 0.25)
Cmk.axislegend(ax1,
    [l1, l2, sc1, sc2],
    [
    &quot;F-Statistic(1, 6) [Dsts.Normal(25, 3), n = 4]&quot;,
    &quot;L-Statistic [Dsts.Normal(25, 3), n = 4]&quot;,
    &quot;L-Statistic [Dsts.Normal(100, 50), n = 4]&quot;,
    &quot;L-Statistic [Dsts.Normal(25, 3), n = 8]&quot;
    ],
    &quot;Distributions
(num groups = 2,
n - num observations per gorup)&quot;,
    position=:rt)
fig</code></pre>
<p>Behold</p>
<figure>
<img src="./images/fAndLDistCh05Ex2.png" id="fig:fAndLDistCh05Ex2" alt="Figure 19: Experimental F- and L-Distributions." /><figcaption aria-hidden="true">Figure 19: Experimental F- and L-Distributions.</figcaption>
</figure>
<p>Wow, what a beauty.</p>
<p>A few points of notice. Before, we calculated the probability (<code>lStatProb</code>) of getting the L-Statistic value greater than the vertical light blue line (the area under the blue curve to the right of that line). This is a one tail probability only. Interestingly, for the L-Distribution the mean and sd in the population of origin are not that important (blue circles for <code>Dsts.Normal(100, 50)</code> lie exactly on the blue line for <code>Dsts.Normal(25, 3)</code>). However, the number of groups and the number of observations per group affect the shape of the distribution (blue xcrosses for <code>Dsts.Normal(25, 3) n = 8</code> diverge from the blue curve for <code>Dsts.Normal(25, 3) n = 4</code>).</p>
<p>The same is true for the F-Distribution. That is why the F-Distribution depends only on the degrees of freedom (<code>Dsts.FDist(dfGroup, dfResidual)</code>). The degrees of freedom depend on the number of groups and the number of observations per group.</p>
<h3 data-number="5.8.3" id="sec:compare_contin_data_ex3_solution"><span class="header-section-number">5.8.3</span> Solution to Exercise 3</h3>
<p>OK, let’s start with functions for checking the assumptions</p>
<pre class="language-julia"><code>function areAllDistributionsNormal(vects::Vector{&lt;:Vector{&lt;:Real}})::Bool
    return [Pg.normality(v).pval[1] for v in vects] |&gt;
        pvals -&gt; map(pv -&gt; pv &gt; 0.05, pvals) |&gt;
        all
end

function areAllVariancesEqual(vects::Vector{&lt;:Vector{&lt;:Real}})
    return Htests.FlignerKilleenTest(vects...) |&gt;
        Htests.pvalue |&gt; pv -&gt; pv &gt; 0.05
end</code></pre>
<p>The functions above are basically just wrappers around the code we wrote in Section <a href="./compare_contin_data_post_hoc_tests.html#sec:compare_contin_data_post_hoc_tests">5.5</a>. Now, time for <code>getPValUnpairedTest</code></p>
<pre class="language-julia"><code>function getPValUnpairedTest(
    v1::Vector{&lt;:Real}, v2::Vector{&lt;:Real})::Float64

    normality::Bool = areAllDistributionsNormal([v1, v2])
    homogeneity::Bool = areAllVariancesEqual([v1, v2])

    return (
        (normality &amp;&amp; homogeneity) ? Htests.EqualVarianceTTest(v1, v2) :
        (normality) ? Htests.UnequalVarianceTTest(v1, v2) :
        Htests.MannWhitneyUTest(v1,v2)
        ) |&gt; Htests.pvalue
end</code></pre>
<p>The code is rather self-explanatory, of course if you remember the ternary expression from Section <a href="./julia_language_decision_making.html#sec:ternary_expression">3.5.2</a> and Section <a href="./julia_language_exercises_solutions.html#sec:julia_language_exercise4_solution">3.9.4</a>.</p>
<p>Let’s test our newly created function with the data from Section <a href="./compare_contin_data_two_samp_ttest.html#sec:compare_contin_data_unpaired_ttest">5.3.2</a> (<code>miceBwt</code>)</p>
<pre class="language-julia"><code>getPValUnpairedTest([miceBwt[!, n] for n in Dfs.names(miceBwt)]...) |&gt;
x -&gt; round(x, digits=4)</code></pre>
<p>0.0804</p>
<p>The p-value is the same as in Section <a href="./compare_contin_data_two_samp_ttest.html#sec:compare_contin_data_unpaired_ttest">5.3.2</a> (as it should be), but this time we didn’t have to explicitly check the assumptions before applying the appropriate test.</p>
<h3 data-number="5.8.4" id="sec:compare_contin_data_ex4_solution"><span class="header-section-number">5.8.4</span> Solution to Exercise 4</h3>
<p>First, let’s start with a helper function that will return us all the possible pairs from a vector.</p>
<pre class="language-julia"><code>function getUniquePairs(names::Vector{T})::Vector{Tuple{T,T}} where {T}

    @assert (length(names) &gt;= 2) &quot;the input must be of length &gt;= 2&quot;

    uniquePairs::Vector{Tuple{T,T}} =
        Vector{Tuple{T,T}}(undef, binomial(length(names), 2))
    currInd::Int = 1

    for i in eachindex(names)[1:(end-1)]
        for j in eachindex(names)[(i+1):end]
            uniquePairs[currInd] = (names[i], names[j])
            currInd += 1
        end
    end

    return uniquePairs
end</code></pre>
<p>The function is generic, so it can be applied to vector of any type (<code>T</code>), here designed as <code>Vector{T}</code>. It starts by initializing an empty vector (<code>uniquePairs</code>) to hold the results. The initialization takes the following form: <code>Vector{typeOfVectElements}(iniaialValues, lengthOfTheVector)</code>. The vector is filled with <code>undef</code>s (undefined values, some garbage) as placeholders. The size of the new vector is calculated by the <a href="https://docs.julialang.org/en/v1/base/math/#Base.binomial">binomial</a> function. It is applied in the form <code>binomial(numValuesToChooseFrom, numValsPerGroup)</code> and returns the number of possible groups of a given size. The rest is just iteration (<code>for</code> loops) over the indexes (<code>eachindex</code>) of the <code>names</code> vector to get all the possible pairs. Let’s quickly check if the function works as expected.</p>
<pre class="language-julia"><code>(
getUniquePairs([10, 20]),
getUniquePairs([1.1, 2.2, 3.3]),
getUniquePairs([&quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;]),
)</code></pre>
<pre class="output"><code>([(10, 20)],
 [(1.1, 2.2), (1.1, 3.3), (2.2, 3.3)],
 [(&quot;w&quot;, &quot;x&quot;), (&quot;w&quot;, &quot;y&quot;), (&quot;w&quot;, &quot;z&quot;), (&quot;x&quot;, &quot;y&quot;), (&quot;x&quot;, &quot;z&quot;), (&quot;y&quot;, &quot;z&quot;)])</code></pre>
<p>OK, now it’s time for <code>getPValsUnpairedTests</code></p>
<pre class="language-julia"><code># df - DataFrame: each column continuous variable
# returns uncorrected p-values
function getPValsUnpairedTests(
    df::Dfs.DataFrame)::Dict{Tuple{String,String},Float64}

    pairs::Vector{Tuple{String,String}} = getUniquePairs(Dfs.names(df))
    pvals::Vector{Float64} = [
        getPValUnpairedTest(df[!, a], df[!, b])
        for (a, b) in pairs
    ]

    return Dict(pairs[i] =&gt; pvals[i] for i in eachindex(pairs))
end</code></pre>
<p>First, we obtain the pairs of group names that we will compare later (<code>pairs</code>). In the next few lines we use for comprehension to obtain the p-values. Since each element of <code>pairs</code> vector is a tuple (e.g. <code>[("spA", "spB"), etc.]</code>) we assign its elements to <code>a</code> and <code>b</code> (<code>for (a, b)</code>) and pass them to <code>df</code> to get the values of interest (e.g. <code>df[!, a]</code>). The values are send to <code>getPValUnpairedTest</code> from the previous section. We terminate (<code>return</code>) with another comprehension that creates a dictionary with the desired result.</p>
<p>Let’s see how the function works and compare the results with the ones we obtained in Section <a href="./compare_contin_data_post_hoc_tests.html#sec:compare_contin_data_post_hoc_tests">5.5</a>.</p>
<pre class="language-julia"><code>getPValsUnpairedTests(miceBwtABC)</code></pre>
<pre class="output"><code>Dict{Tuple{String, String}, Float64} with 3 entries:
  (&quot;spA&quot;, &quot;spB&quot;) =&gt; 0.0251115
  (&quot;spA&quot;, &quot;spC&quot;) =&gt; 0.000398545
  (&quot;spB&quot;, &quot;spC&quot;) =&gt; 0.0493322</code></pre>
<p>OK, the uncorrected p-values are the same.</p>
<p>Now, the improved version.</p>
<pre class="language-julia"><code># df - DataFrame: each column continuous variable
# returns corrected p-values
function getPValsUnpairedTests(
    df::Dfs.DataFrame,
    multCorr::Type{M}
)::Dict{Tuple{String,String},Float64} where {M&lt;:Mt.PValueAdjustment}

    pairs::Vector{Tuple{String,String}} = getUniquePairs(Dfs.names(df))
    pvals::Vector{Float64} = [
        getPValUnpairedTest(df[!, a], df[!, b])
        for (a, b) in pairs
    ]
    pvals = Mt.adjust(pvals, multCorr())

    return Dict(pairs[i] =&gt; pvals[i] for i in eachindex(pairs))
end</code></pre>
<p>Don’t worry about the strange type declarations like <code>::Type{M}</code> and <code>where {M&lt;:Mt.PValueAdjustment}</code>. I added them for the sake of consistency (after reading the code in <a href="https://github.com/juliangehring/MultipleTesting.jl">the package repo</a> and some try and error). When properly called, the function should work equally well without those parts.</p>
<p>Anyway, it wasn’t that bad, we basically just added a small piece of code (<code>multCorr</code> in the arguments list and <code>pvals = Mt.adjust(pvals, multCorr())</code> in the function body) similar to the one in Section <a href="./compare_contin_data_multip_correction.html#sec:compare_contin_data_multip_correction">5.6</a>.</p>
<p>Let’s see how it works.</p>
<pre class="language-julia"><code># Bonferroni correction
getPValsUnpairedTests(miceBwtABC, Mt.Bonferroni)</code></pre>
<pre class="output"><code>Dict{Tuple{String, String}, Float64} with 3 entries:
  (&quot;spA&quot;, &quot;spB&quot;) =&gt; 0.0753345
  (&quot;spA&quot;, &quot;spC&quot;) =&gt; 0.00119563
  (&quot;spB&quot;, &quot;spC&quot;) =&gt; 0.147997</code></pre>
<p>That looks quite alright. Time for one more swing.</p>
<pre class="language-julia"><code># Benjamini-Hochberg correction
getPValsUnpairedTests(miceBwtABC, Mt.BenjaminiHochberg)</code></pre>
<pre class="output"><code>Dict{Tuple{String, String}, Float64} with 3 entries:
  (&quot;spA&quot;, &quot;spB&quot;) =&gt; 0.0376673
  (&quot;spA&quot;, &quot;spC&quot;) =&gt; 0.00119563
  (&quot;spB&quot;, &quot;spC&quot;) =&gt; 0.0493322</code></pre>
<p>Again, the p-values appear to be the same as those we saw in Section <a href="./compare_contin_data_multip_correction.html#sec:compare_contin_data_multip_correction">5.6</a>.</p>
<h3 data-number="5.8.5" id="sec:compare_contin_data_ex5_solution"><span class="header-section-number">5.8.5</span> Solution to Exercise 5</h3>
<p>OK, let’s do this step by step. First let’s draw a bare box-plot (no group names, no significance markers, titles, etc.).</p>
<p>The docs for <a href="https://docs.makie.org/stable/examples/plotting_functions/boxplot/index.html#boxplot">Cmk.boxplot</a> show that to do that we need two vectors for xs and ys (values to be placed on the x- and y-axis respectively). Both need to be of numeric types. We can achieve it by typing, e.g.</p>
<pre class="language-julia"><code># Step 1
ex5nrows = size(miceBwtABC)[1] #1
ex5names = Dfs.names(miceBwtABC) #2
ex5xs = repeat(eachindex(ex5names), inner=ex5nrows) #3
ex5ys = [miceBwtABC[!, n] for n in ex5names] #4
ex5ys = vcat(ex5ys...) #5

Cmk.boxplot(ex5xs, ex5ys)</code></pre>
<p>In the first line (<code>#1</code>) we get the dimensions of our data frame, <code>size(miceBwtABC)</code> returns a tuple <code>(numberOfRows, numberOfColumns)</code> from which we take only the first part (<code>numberOfRows</code>) that we will need later. In line 3 (<code>#3</code>) we assign a number to the names (<code>eachindex(vect)</code> returns a sequence <code>1:length(vect)</code>, e.g. <code>[1, 2, 3]</code>). We multiply each number the same amount of times (<code>ex5nrows</code>) using <code>repeat</code> (e.g. <code>repeat([1, 2, 3], inner=2)</code> returns <code>[1, 1, 2, 2, 3, 3]</code>). In line 4 and 5 (<code>#4</code> and <code>#5</code>) we take all the body weights from columns and put them into a one long vector (<code>ex5ys</code>). We end up with two vectors: groups coded as integers and body weights. Finally, we check if it works by running <code>Cmk.boxplot(ex5xs, ex5ys)</code>. The result is below.</p>
<figure>
<img src="./images/ch05ex5step1.png" id="fig:ch05ex5step1" alt="Figure 20: Box-plot for exercise 5. Step 1." /><figcaption aria-hidden="true">Figure 20: Box-plot for exercise 5. Step 1.</figcaption>
</figure>
<p>Now, let’s add title, label the axis, etc.</p>
<pre class="language-julia"><code># Step 2
fig = Cmk.Figure()
Cmk.Axis(fig[1, 1], xticks=(eachindex(ex5names), ex5names),
    title=&quot;Body mass of three mice species&quot;,
    xlabel=&quot;species name&quot;, ylabel=&quot;body mass [g]&quot;)
Cmk.boxplot!(fig[1, 1], ex5xs, ex5ys)
fig</code></pre>
<p>The only new part here is the <code>xticks</code> argument. It takes a tuple of ticks on x axis (<code>1:3</code> in Figure <a href="#fig:ch05ex5step1">20</a>) and a vector of strings (<code>ex5names</code>) to be displayed instead of those values. The result is seen below.</p>
<figure>
<img src="./images/ch05ex5step2.png" id="fig:ch05ex5step2" alt="Figure 21: Box-plot for exercise 5. Step 2." /><figcaption aria-hidden="true">Figure 21: Box-plot for exercise 5. Step 2.</figcaption>
</figure>
<p>Let’s move on to the significance markers. First, let’s hard-code them and produce a plot (just to see if it works), then we will introduce some improvements.</p>
<pre class="language-julia"><code># Step 3
fig = Cmk.Figure()
Cmk.Axis(fig[1, 1], xticks=(eachindex(ex5names), ex5names),
    title=&quot;Body mass of three mice species&quot;,
    xlabel=&quot;species name&quot;, ylabel=&quot;body mass [g]&quot;)
Cmk.boxplot!(fig[1, 1], ex5xs, ex5ys)
Cmk.text!(fig[1, 1],
    eachindex(ex5names), [30, 30, 30],
    text=[&quot;&quot;, &quot;a&quot;, &quot;ab&quot;],
    align=(:center, :top), fontsize=20)
fig</code></pre>
<p>OK, we’re almost there (see figure below).</p>
<figure>
<img src="./images/ch05ex5step3.png" id="fig:ch05ex5step3" alt="Figure 22: Box-plot for exercise 5. Step 3." /><figcaption aria-hidden="true">Figure 22: Box-plot for exercise 5. Step 3.</figcaption>
</figure>
<p>However, it appears that we still need a few things:</p>
<ol type="1">
<li>a way to generate y-values for <code>Cmk.text!</code> (for now it is <code>[30, 30, 30]</code>, but other dataframe may have different value ranges, e.g. [200-250], then the markers would be placed too low)</li>
<li>a way to generate the markers (<code>["", "a", "ab"]</code> based on p-values) over the appropriate boxes</li>
</ol>
<p>First problem can be solved in the following way:</p>
<pre class="language-julia"><code># Step 4
ex5marksYpos = [maximum(miceBwtABC[!, n]) for n in ex5names] #1
ex5marksYpos = map(mYpos -&gt; round(Int, mYpos * 1.1), ex5marksYpos) #2
ex5upYlim = maximum(ex5ys * 1.2) |&gt; x -&gt; round(Int, x) #3
ex5downYlim = minimum(ex5ys * 0.8) |&gt; x -&gt; round(Int, x) #4</code></pre>
<p>Here, in the first line (<code>#1</code>) we get maximum values from every group. Then (<code>#2</code>) we increase them by 10% (<code>* 1.1</code>) and round them to the closest integers (<code>round(Int,</code>). At this height (y-axis) we are going to place our significance markers. Additionally, in lines 3 and 4 (<code>#3</code> and <code>#4</code>) we found the maximum and minimum values in all groups. We increase (<code>* 1.2</code>) and decrease (<code>* 0.8</code>) the values by 20%. The rounded (to the nearest integer) values will be the maximum and minimum values displayed on the y-axis of our graph.</p>
<p>Now, time for a function that will translate p-values to significance markers.</p>
<pre class="language-julia"><code># Step 5
function getMarkers(
    pvs::Dict{Tuple{String,String},Float64},
    groupsOrder=[&quot;spA&quot;, &quot;spB&quot;, &quot;spC&quot;],
    markerTypes::Vector{String}=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],
    cutoffAlpha::Float64=0.05)::Vector{String}

    @assert (
        length(groupsOrder) == length(markerTypes)
    ) &quot;different groupSOrder and markerTypes lengths&quot;
    @assert (0 &lt;= cutoffAlpha &lt;= 1) &quot;cutoffAlpha must be in range [0-1]&quot;

    markers::Vector{String} = repeat([&quot;&quot;], length(groupsOrder))
    tmpInd::Int = 0

    for i in eachindex(groupsOrder)
        for ((g1, g2), pv) in pvs
            if (groupsOrder[i] == g1) &amp;&amp; (pv &lt; cutoffAlpha)
                tmpInd = findfirst(x -&gt; x == g2, groupsOrder)
                markers[tmpInd] *= markerTypes[i]
            end
        end
    end

    return markers
end</code></pre>
<p>Here, <code>getMarkers</code> accepts p-values in the format returned by <code>getPValsUnpairedTests</code> defined in Section <a href="./compare_contin_data_exercises_solutions.html#sec:compare_contin_data_ex4_solution">5.8.4</a>. Another input argument is <code>groupsOrder</code> which contains the position of groups (boxes, x-axis labels) in Figure <a href="#fig:ch05ex5step3">22</a> from left to right. The third argument is <code>makrerTypes</code> so a symbol that is to be used if a statistical difference for a given group is found.</p>
<p>The function defines <code>markers</code> (the strings placed over each box with <code>Cmk.txt</code>) initialized with a vector of empty strings. Next, it walks through each index in group (<code>eachindex(groups)</code>) and checks the <code>((g1, g2), pv)</code> in p-values (<code>pvs</code>). If <code>g1</code> is equal to the examined group (<code>groups[i] == g1</code>) and the p-value (<code>pv</code>) is below the cutoff level then the appropriate marker (<code>markerTypes[i]</code>) is inserted by <a href="https://docs.julialang.org/en/v1/manual/strings/#man-concatenation">string concatenation</a> with an <a href="https://docs.julialang.org/en/v1/manual/mathematical-operations/#Updating-operators">update operator</a> (<code>*=</code>). Which maker to change is determined by the index of <code>g2</code> in the <code>groups</code> returned by <a href="https://docs.julialang.org/en/v1/base/strings/#Base.findfirst-Tuple%7BAbstractString,%20AbstractString%7D">findfirst</a> function. In general, <code>g2</code> receives a marker when it is statistically different from <code>g1</code> (<code>pv &lt; cutoffAlpha</code>).</p>
<p>Let’s test our function</p>
<pre class="language-julia"><code>(
getMarkers(
    getPValsUnpairedTests(miceBwtABC, Mt.BenjaminiHochberg),
    [&quot;spA&quot;, &quot;spB&quot;, &quot;spC&quot;],
    [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],
    0.05),

getPValsUnpairedTests(miceBwtABC, Mt.BenjaminiHochberg)
)</code></pre>
<pre class="output"><code>([&quot;&quot;, &quot;a&quot;, &quot;ab&quot;], 
Dict((&quot;spA&quot;, &quot;spB&quot;) =&gt; 0.0376672521079031,
(&quot;spA&quot;, &quot;spC&quot;) =&gt; 0.001195633577293774,
(&quot;spB&quot;, &quot;spC&quot;) =&gt; 0.049332195639921715))</code></pre>
<p>The markers appear to be OK (they reflect the p-values well).</p>
<p>Now, it is time to pack it all into a separate function</p>
<pre class="language-julia"><code># Step 6

# the function should work fine for up to 26 groups in the df&#39;s columns
function drawBoxplot(
    df::Dfs.DataFrame, title::String,
    xlabel::String, ylabel::String)::Cmk.Figure

    nrows, _ = size(df)
    ns::Vector{String} = Dfs.names(df)
    xs = repeat(eachindex(ns), inner=nrows)
    ys = [df[!, n] for n in ns]
    ys = vcat(ys...)
    marksYpos = [maximum(df[!, n]) for n in ns]
    marksYpos = map(mYpos -&gt; round(Int, mYpos * 1.1), marksYpos)
    upYlim = maximum(ys * 1.2) |&gt; x -&gt; round(Int, x)
    downYlim = minimum(ys * 0.8) |&gt; x -&gt; round(Int, x)
    alphabet::String = &quot;abcdefghijklmnopqrstuvwxyz&quot;
    markerTypes::Vector{String} = split(alphabet, &quot;&quot;)
    markers::Vector{String} = getMarkers(
        getPValsUnpairedTests(df, Mt.BenjaminiHochberg),
        ns,
        markerTypes[1:length(ns)],
        0.05
    )

    fig = Cmk.Figure()
    Cmk.Axis(fig[1, 1], xticks=(eachindex(ns), ns),
        title=title,
        xlabel=xlabel, ylabel=ylabel)
    Cmk.boxplot!(fig[1, 1], xs, ys)
    Cmk.ylims!(downYlim, upYlim)
    Cmk.text!(fig[1, 1],
        eachindex(ns), marksYpos,
        text=markers,
        align=(:center, :top), fontsize=20)

    return fig
end</code></pre>
<p>and run it</p>
<pre class="language-julia"><code>drawBoxplot(miceBwtABC,
    &quot;Body mass of three mice species&quot;,
    &quot;species name&quot;,
    &quot;body mass [g]&quot;
)</code></pre>
<p>And voilà this is your result</p>
<figure>
<img src="./images/ch05ex5step4.png" id="fig:ch05ex5step4" alt="Figure 23: Box-plot of body mass of three mice species. Steps 1-6 (completed). a - difference vs. spA (p &lt; 0.05), b - difference vs. spB (p &lt; 0.05)." /><figcaption aria-hidden="true">Figure 23: Box-plot of body mass of three mice species. Steps 1-6 (completed). a - difference vs. spA (p &lt; 0.05), b - difference vs. spB (p &lt; 0.05).</figcaption>
</figure>
<p>You could make the function more plastic, e.g. by moving some of its insides to its argument list. But this form will do for now. You may want to test the function with some other output, even with <code>miceBwt</code> from Section <a href="./compare_contin_data_two_samp_ttest.html#sec:compare_contin_data_two_samp_ttest">5.3</a> (here it should draw a box-plot with no statistical significance markers).</p>
<blockquote>
<p><strong><em>Note:</em></strong> The code we developed in the exercises (e.g. <code>getPValsUnpairedTests</code>, <code>drawBoxplot</code>) is to help us automate stuff, still it shouldn’t be applied automatically (think before you leap).</p>
</blockquote>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>