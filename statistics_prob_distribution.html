<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Probability distribution - Romeo and Julia, where Romeo is Basic Statistics</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia, where Romeo is Basic Statistics</a>
</div><br />
<span class="books-subtitle">

</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises_solutions.html"><b>5.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_imports.html"><b>6.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_flashback.html"><b>6.2</b> Flashback</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_chisq_test.html"><b>6.3</b> Chi squared test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_fisher_exact_text.html"><b>6.4</b> Fisher’s exact test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_bigger_table.html"><b>6.5</b> Bigger table</a></li>
<li><a class="menu-level-2" href="./compare_categ_test_for_independence.html"><b>6.6</b> Test for independence</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises.html"><b>6.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises_solutions.html"><b>6.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./association.html"><b>7</b> Association</a></li>
<li><a class="menu-level-2" href="./association_imports.html"><b>7.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./association_lin_relation.html"><b>7.2</b> Linear relation</a></li>
<li><a class="menu-level-2" href="./association_covariance.html"><b>7.3</b> Covariance</a></li>
<li><a class="menu-level-2" href="./association_correlation.html"><b>7.4</b> Correlation</a></li>
<li><a class="menu-level-2" href="./association_corr_pitfalls.html"><b>7.5</b> Correlation Pitfalls</a></li>
<li><a class="menu-level-2" href="./association_exercises.html"><b>7.6</b> Exercises - Association</a></li>
<li><a class="menu-level-2" href="./association_exercises_solutions.html"><b>7.7</b> Solutions - Association</a></li>
<li><a class="menu-level-1" href="./prediction.html"><b>8</b> Prediction</a></li>
<li><a class="menu-level-2" href="./prediction_imports.html"><b>8.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./pred_simple_lin_reg.html"><b>8.2</b> Simple Linear Regression</a></li>
<li><a class="menu-level-2" href="./pred_multiple_lin_reg.html"><b>8.3</b> Multiple Linear Regressi..</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>9</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="4.5" id="sec:statistics_prob_distribution"><span class="header-section-number">4.5</span> Probability distribution</h2>
<p>Another important concept worth knowing is that of <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a>. Let’s explore it with some, hopefully interesting, examples.</p>
<p>First, imagine I offer Your a bet. You roll two six-sided dice. If the sum of the dots is 12 then I give you $125, otherwise you give me $5. Hmm, sounds like a good bet, doesn’t it? Well, let’s find out. By flexing our probabilistic muscles and using a computer simulation this should not be too hard to answer.</p>
<pre class="language-julia"><code>function getSumOf2DiceRoll()::Int
    return sum(Rand.rand(1:6, 2))
end

Rand.seed!(321)
numOfRolls = 100_000
diceRolls = [getSumOf2DiceRoll() for _ in 1:numOfRolls]
diceCounts = getCounts(diceRolls)
diceProbs = getProbs(diceCounts)</code></pre>
<p>Here, we rolled two 6-sided dice 100 thousand (<span class="math inline">\(10^5\)</span>) times. The code introduces no new elements. The functions: <code>getCounts</code>, <code>getProbs</code>, <code>Rand.seed!</code> were already introduced in the previous chapter (see Section <a href="./statistics_prob_theor_practice.html#sec:statistics_prob_theor_practice">4.4</a>). And the <code>for _ in</code> construct we met while talking about for loops (see Section <a href="./julia_language_repetition.html#sec:julia_language_for_loops">3.6.1</a>).</p>
<p>So, let’s take a closer look at the result.</p>
<pre class="language-julia"><code>(diceCounts[12], diceProbs[12])</code></pre>
<pre class="output"><code>(2780, 0.0278)</code></pre>
<p>It seems that out of 100’000 rolls with two six-sided dice only 2780 gave us two sixes (6 + 6 = 12), so the experimental probability is equal to 0.0278. But is it worth it? From a point of view of a single person (remember the bet is you vs. me) a person got probability of <code>diceProbs[12] =</code> 0.0278 to win $125 and a probability of <code>sum([get(diceProbs, i, 0) for i in 2:11]) =</code> 0.9722 to lose $5. Since all the probabilities (for 2:12) add up to 1, the last part could be rewritten as <code>1 - diceProbs[12] =</code> 0.9722. Using Julia I can write this in the form of an equation like so:</p>
<pre class="language-julia"><code>function getOutcomeOfBet(probWin::Float64, moneyWin::Real,
                         probLose::Float64, moneyLose::Real)::Float64
    # in mathematics first we do multiplication (*), then subtraction (-)
    return probWin * moneyWin - probLose * moneyLose
end

outcomeOf1bet = getOutcomeOfBet(diceProbs[12], 125, 1 - diceProbs[12], 5)

round(outcomeOf1bet, digits=2) # round to cents (1/100th of a dollar)</code></pre>
<p>-1.39</p>
<p>In total you are expected to lose $ 1.39.</p>
<p>Now some people may say “Phi! What is $1.39 if I can potentially win $125 in a few tries.” It seems to me those are emotions (and perhaps greed) talking, but let’s test that too.</p>
<p>If 200 people make that bet (100 bet $5 on 12 and 100 bet $125 on the other result) we would expect the following outcome:</p>
<pre class="language-julia"><code>numOfBets = 100

outcomeOf100bets = (diceProbs[12] * numOfBets * 125) -
    ((1 - diceProbs[12]) * numOfBets * 5)
# or
outcomeOf100bets = ((diceProbs[12] * 125) - ((1 - diceProbs[12]) * 5)) * 100
# or simply
outcomeOf100bets = outcomeOf1bet * numOfBets

round(outcomeOf100bets, digits=2)</code></pre>
<p>-138.6</p>
<p>OK. So, above we introduced a few similar ways to calculate that. The result of the bet is -138.6. In reality roughly 97 people that bet $5 on two sixes (6 + 6 = 12) lost their money and only 3 of them won $125 dollars which gives us <span class="math inline">\(3*\$125 - 97*\$5= -\$110\)</span> (the numbers are not exact because based on probability we got 2.78 people and not 3, and so on).</p>
<p>Interestingly, this is the same as if you placed that same bet with me 100 times. Ninety-seven times you would have lost $5 and only 3 times you would have won $125 dollars. This would leave you over $110 poorer and me over $110 richer.</p>
<p>It seems that instead of betting on 12 (two sixes) many times you would be better off had you started a casino or a lottery. Then you should find let’s say 1’000 people daily that will take that bet (or buy $5 ticket) and get you $ 1386.0 (<code>outcomeOf1bet * 1000</code>) richer every day (well, probably less, because you would have to pay some taxes, still this makes a pretty penny).</p>
<p>OK, you saw right through me and you don’t want to take that bet. Hmm, but what if I say a nice, big “I’m sorry” and offer you another bet. Again, you roll two six-sided dice. If you get 11 or 12 I give you $90 otherwise you give me $10. This time you know right away what to do:</p>
<pre class="language-julia"><code>pWin = sum([diceCounts[i] for i in 11:12]) / numOfRolls
# or
pWin = sum([diceProbs[i] for i in 11:12])

pLose = 1 - pWin

round(pWin * 90 - pLose * 10, digits=2)</code></pre>
<p>-1.54</p>
<p>So, to estimate the probability we can either add number of occurrences of 11 and 12 and divide it by the total occurrences of all events OR, as we learned in the previous chapter (see Section <a href="./statistics_intro_probability_properties.html#sec:statistics_intro_probability_properties">4.3</a>), we can just add the probabilities of 11 and 12 to happen. Then we proceed with calculating the expected outcome of the bet and find out that I wanted to trick you again (“I’m sorry. Sorry.”).</p>
<p>Now, using this method (that relies on probability distribution) you will be able to look through any bet that I will offer you and choose only those that serve you well. OK, so what is a probability distribution anyway, well it is just the value that probability takes for any possible outcome. We can represent it graphically by using any of <a href="https://juliapackages.com/c/graphical-plotting">Julia’s plotting libraries</a>.</p>
<p>Here, I’m going to use <a href="https://docs.makie.org/stable/">Makie.jl</a> which seems to produce pleasing to the eye plots and is simple enough (that’s what I think after I read its <a href="https://docs.makie.org/stable/tutorials/basic-tutorial/">Basic Tutorial</a>). Nota bene also its error messages are quite informative (once you learn to read them).</p>
<pre class="language-julia"><code>import CairoMakie as Cmk

function getSortedKeysVals(d::Dict{T1,T2})::Tuple{
    Vector{T1},Vector{T2}} where {T1,T2}

    sortedKeys::Vector{T1} = keys(d) |&gt; collect |&gt; sort
    sortedVals::Vector{T2} = [d[k] for k in sortedKeys]
    return (sortedKeys, sortedVals)
end

xs1, ys1 = getSortedKeysVals(diceCounts)
xs2, ys2 = getSortedKeysVals(diceProbs)

fig = Cmk.Figure()
Cmk.barplot(fig[1, 1:2], xs1, ys1,
    color=&quot;red&quot;,
    axis=(; # the &#39;;&#39; needs to be here
        title=&quot;Rolling 2 dice 100&#39;000 times&quot;,
        xlabel=&quot;Sum of dots&quot;,
        ylabel=&quot;Number of occurrences&quot;,
        xticks=2:12)
)
Cmk.barplot(fig[2, 1:2], xs2, ys2,
    color=&quot;blue&quot;,
    axis=(; # the &#39;;&#39; needs to be here
        title=&quot;Rolling 2 dice 100&#39;000 times&quot;,
        xlabel=&quot;Sum of dots&quot;,
        ylabel=&quot;Probability of occurrence&quot;,
        xticks=2:12)
)
fig</code></pre>
<p>First, we extracted the sorted keys and values from our dictionaries (<code>diceCounts</code> and <code>diceProbs</code>) using <code>getSortedKeysVals</code>. The only new element here is <code>|&gt;</code> operator. It’s role is <a href="https://docs.julialang.org/en/v1/manual/functions/#Function-composition-and-piping">piping</a> the output of one function as input to another function. So <code>keys(d) |&gt; collect |&gt; sort</code> is just another way of writing <code>sort(collect(keys(d)))</code>. In both cases first we run <code>keys(d)</code>, then we use the result of this function as an input to <code>collect</code> function, and finally pass its result to <code>sort</code> function. Out of the two options, the one with <code>|&gt;</code> seems to be clearer to me.</p>
<p>Regarding the <code>getSortedKeysVals</code> it returns a tuple of sorted keys and values (that correspond with the keys). In line <code>xs1, ys1 = getSortedKeysVals(diceCounts)</code> we unpack then values and assign them to <code>xs1</code> (it gets sorted keys) and <code>ys1</code> (it get values that correspond with the keys). We do likewise for <code>diceProbs</code> in the line below.</p>
<p>In the next step we draw the distributions as bar plots (<code>Cmk.barplot</code>). The code seems to be pretty self explanatory after you read <a href="https://docs.makie.org/stable/tutorials/basic-tutorial/">the tutorial</a> that I just mentioned. Two points of notice here (in case you wanted to know more): 1) the <code>axis=</code>, <code>color=</code>, <code>xlabel=</code>, etc. are so called <a href="https://docs.julialang.org/en/v1/manual/functions/#Keyword-Arguments">keyword arguments</a>, 2) the <code>axis</code> keyword argument accepts a so called <a href="https://docs.julialang.org/en/v1/base/base/#Core.NamedTuple">named tuple</a>. OK, let’s get back to the graph. The number of counts (number of occurrences) on Y-axis is displayed in a scientific notation, i.e. <span class="math inline">\(1.0 x 10^4\)</span> is 10’000 (one with 4 zeros) and <span class="math inline">\(1.5 = 10^4\)</span> is 15’000.</p>
<blockquote>
<p><strong><em>Note:</em></strong> Because of the compilation process running Julia’s plots for the first time may be slow. If that is the case you may try some tricks recommended by package designers, e.g. <a href="http://gadflyjl.org/stable/#Compilation">this one from the creators of Gadfly.jl</a>.</p>
</blockquote>
<figure>
<img src="./images/rolling2diceCountsProbs.png" id="fig:twoDiceCountsProbs" alt="Figure 3: Rolling two 6-sided dice (counts and probabilities)." /><figcaption aria-hidden="true">Figure 3: Rolling two 6-sided dice (counts and probabilities).</figcaption>
</figure>
<p>OK, but why did I even bother to talk about probability distribution (except for the great enlightenment it might have given to you)? Well, because it is important. It turns out that in statistics one relies on many distributions. For instance:</p>
<ul>
<li><p>We want to know if people in city A are taller than in city B. We take at random 10 people from each of the cities, we measure them and run a famous <a href="https://en.wikipedia.org/wiki/Student%27s_t-test">Student’s T-test</a> to find out. It gives us the probability that helps us answer our question. It does so based on a <a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">t-distribution</a>.</p></li>
<li><p>We want to know if cigarette smokers are more likely to believe in ghosts. What we do is we find random groups of smokers and non-smokers and ask them about it (Do you believe in ghosts?). We record the results and run a <a href="https://en.wikipedia.org/wiki/Chi-squared_test">chi squared test</a> that gives us the probability that helps us answer our question. It does so based on a <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">chi squared distribution</a>.</p></li>
</ul>
<p>OK, that should be enough for now. Take some rest, and when you’re ready continue with the next chapter.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>