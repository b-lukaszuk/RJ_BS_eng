<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Multiplicity correction - Romeo and Julia</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia</a>
</div><br />
<span class="books-subtitle">
where Romeo is Basic Statistics
</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>6</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="5.6" id="sec:compare_contin_data_multip_correction"><span class="header-section-number">5.6</span> Multiplicity correction</h2>
<p>In the previous section we performed a pairwise t-test for the following comparisons:</p>
<ul>
<li><code>spA</code> vs <code>spB</code>,</li>
<li><code>spA</code> vs <code>spC</code>,</li>
<li><code>spB</code> vs <code>spC</code>.</li>
</ul>
<p>The obtained p-values were</p>
<pre class="language-julia"><code>postHocPvals</code></pre>
<pre class="output"><code>[0.025111501405268754, 0.0003985445257645916, 0.049332195639921715]</code></pre>
<p>Based on that we concluded that every group mean differs from every other group mean (all p-values are lower than the cutoff level for <span class="math inline">\(\alpha\)</span> equal to 0.05). However, there is a small problem with this approach (see the explanation below).</p>
<p>In Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_errors">4.7.5</a> we said that it is impossible to reduce the type 1 error (<span class="math inline">\(\alpha\)</span>) probability to 0. Therefore if all our null hypothesis (<span class="math inline">\(H_{0}\)</span>) were true we need to accept the fact that we will report some false positive findings. All we can do is to keep that number low. How low? Read on.</p>
<p>Imagine you are testing a set of random substances to see if they reduce the size of a <a href="https://en.wikipedia.org/wiki/Neoplasm">tumor</a>, e.g. its diameter. Most likely the vast majority of the tested substances will not work (so let’s assume that in reality all <span class="math inline">\(H_{0}\)</span>s are true). Now imagine, that the result each substance has on the tumor you place in a separate scientific paper and publish in a scientific journal. During your entire scientific career you published 100 papers for 100 different substances. Now the question. How many times would you report a false positive result if the cutoff level for <span class="math inline">\(\alpha\)</span> is 0.05? Pause for a moment and come up with the number. That is easy, 100 papers times 0.05 (probability of false positive) gives us the expected <code>100 * 0.05</code> = 5 false positive reports. BTW. If you got it, congratulations. If not compare the solution with the calculations we did in Section <a href="./statistics_prob_distribution.html#sec:statistics_prob_distribution">4.5</a>. Anyway, you decided that this will be your golden standard, i.e. no more than 5% (<span class="math inline">\(\frac{5}{100}\)</span> = 0.05) of scientific papers with false positives.</p>
<p>But here, in <code>postHocPvals</code> above, you got 3 comparisons and therefore 3 p-values. Imagine that you place such three results into a single scientific paper. Now, the question is: under the conditions given above (all <span class="math inline">\(H_{0}\)</span>s true, cutoff for <span class="math inline">\(\alpha\)</span> = 0.05) how many papers would report false positives if you placed three such comparisons per paper for 100 scientific papers? Think for a moment and come up with the number.</p>
<p>OK, so we got 100 papers, each reporting 3 comparisons (3 p-values), which gives us in total 300 results. Out of them we expect <code>300 * 0.05</code> = 15 to be false positives. Now, we pack those 300 results into 100 scientific papers. In the best case scenario the 15 false positives will land in the first five papers (three false positives per paper, <code>5*3</code> = 15), the remaining 285 true negatives will land in the remaining 95 papers (three true negatives per paper, <code>95*3</code> = 285). The golden standard seems to be kept (<code>5/100</code> = 0.05) The problem is that we got no control over which papers get the false positives. The <a href="https://en.wikipedia.org/wiki/Murphy%27s_law">Murphy’s law</a> states: “Anything that can go wrong will go wrong, and at the worst possible time.” (or in the worst possible way). If so, then the 15 false positives will go to 15 different papers (1 false positive + 2 true negatives per paper), and the remaining <code>285 - 2*15</code> = 255 true negatives will go to the remaining <code>255/3</code> = 85 papers. Here, your golden standard (5% of scientific papers with false positives) is violated (<code>15/100</code> = 0.15).</p>
<p>This is why we cannot just leave the three <code>postHocPvals</code> as they are. We need to act, but what can we do to counteract the problem. Well, if the initial cutoff level for <span class="math inline">\(\alpha\)</span> was 3 times smaller (<code>0.05 / 3</code> = 0.017) then in the case above we would have <code>300 * (0.05/3)</code> ≈ 5.0 false positives to put into 100 papers and everything would be OK even in the worst case scenario. Alternatively, since division is inverse operation to multiplication we could just multiply every p-value by 3 (number of comparisons) and check its significance at the cutoff level for <span class="math inline">\(\alpha\)</span> equal 0.05, like so</p>
<pre class="language-julia"><code>function adjustPvalue(pVal::Float64, by::Int)::Float64
    @assert (0 &lt;= pVal &lt;= 1) &quot;pVal must be in range [0-1]&quot;
    return min(1, pVal*by)
end

function adjustPvalues(pVals::Vector{Float64})::Vector{Float64}
    return adjustPvalue.(pVals, length(pVals))
end

# p-values for comparisons: spA vs spB, spA vs spC, and spB vs spC
adjustPvalues(postHocPvals)</code></pre>
<pre class="output"><code>[0.07533450421580626, 0.0011956335772937748, 0.14799658691976514]</code></pre>
<p>Notice, the since on entry a p-value may be, let’s say, 0.6 then multiplying it by 3 would give us 1.8 which is an impossible value for probability (see Section <a href="./statistics_intro_probability_definition.html#sec:statistics_intro_probability_definition">4.2</a>). That is why we set the upper limit to 1 by using <code>min(1, pVal*by)</code>. Anyway, after adjusting for multiple comparisons only one species differs from the other (<code>spA</code> vs <code>spC</code>, adjusted p-value &lt; 0.05). And this is our final conclusion.</p>
<p>The method we used above (in <code>adjustPvalue</code> and <code>adjustPvalues</code>) is called the <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni correction</a>. It is the simplest method out there (in my opinion) and it is useful if we have a small number of independent comparisons/p-values (let’s say up to 6). For a large number of comparisons you may end up with a paradox:</p>
<ul>
<li>one-way ANOVA (which controls the overall <span class="math inline">\(\alpha\)</span> at the level of 0.05) indicates that there are some statistically significant differences,</li>
<li>the corrected p-values (which rely on different assumptions) show no significant differences.</li>
</ul>
<p>Therefore, for large number of comparisons you may choose a different (less strict) method, e.g. the <a href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Hochberg_procedure">Benjamini-Hochberg procedure</a>. Both of those (Bonferroni and Benjamini-Hochberg) are available in the <a href="https://github.com/juliangehring/MultipleTesting.jl">MultipleTesting</a> package. Observe</p>
<pre class="language-julia"><code>import MultipleTesting as Mt
# p-values for comparisons: spA vs spB, spA vs spC, and spB vs spC
resultsOfThreeAdjMethods = (
    adjustPvalues(postHocPvals),
    Mt.adjust(postHocPvals, Mt.Bonferroni()),
    Mt.adjust(postHocPvals, Mt.BenjaminiHochberg())
)

resultsOfThreeAdjMethods</code></pre>
<pre class="output"><code>([0.07533450421580626, 0.0011956335772937748, 0.14799658691976514],
 [0.07533450421580626, 0.0011956335772937748, 0.14799658691976514],
 [0.03766725210790313, 0.0011956335772937748, 0.049332195639921715])</code></pre>
<p>As expected, the first two lines give the same results (since they both use the same adjustment method). The third line, and a different method, gives a different result/interpretation. A word of caution, you shouldn’t just apply 10 different methods on the obtained p-values and choose the one that produces the greatest number of significant differences. Instead you should choose a correction method a priori (up front, in advance) and stick to it later (make the final decision of which group(s) differ based on the adjusted p-values).</p>
<p>OK, enough of theory, time for some practice. Whenever you’re ready click the right arrow to go to the exercises for this chapter.</p>
<p>To be continued…</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>