<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Exercises - Association - Romeo and Julia, where Romeo is Basic Statistics</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia, where Romeo is Basic Statistics</a>
</div><br />
<span class="books-subtitle">

</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises_solutions.html"><b>5.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_imports.html"><b>6.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_flashback.html"><b>6.2</b> Flashback</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_chisq_test.html"><b>6.3</b> Chi squared test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_fisher_exact_text.html"><b>6.4</b> Fisher’s exact test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_bigger_table.html"><b>6.5</b> Bigger table</a></li>
<li><a class="menu-level-2" href="./compare_categ_test_for_independence.html"><b>6.6</b> Test for independence</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises.html"><b>6.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises_solutions.html"><b>6.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./association.html"><b>7</b> Association</a></li>
<li><a class="menu-level-2" href="./assoc_and_pred_data_imports.html"><b>7.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./association_lin_relation.html"><b>7.2</b> Linear relation</a></li>
<li><a class="menu-level-2" href="./assocociation_covariance.html"><b>7.3</b> Covariance</a></li>
<li><a class="menu-level-2" href="./assoc_and_pred_correlation.html"><b>7.4</b> Correlation</a></li>
<li><a class="menu-level-2" href="./association_corr_pitfalls.html"><b>7.5</b> Correlation Pitfalls</a></li>
<li><a class="menu-level-2" href="./association_exercises.html"><b>7.6</b> Exercises - Association</a></li>
<li><a class="menu-level-2" href="./association_exercises_solutions.html"><b>7.7</b> Solutions - Association</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>8</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="7.6" id="sec:association_exercises"><span class="header-section-number">7.6</span> Exercises - Association</h2>
<p>Just like in the previous chapters here you will find some exercises that you may want to solve to get from this chapter as much as you can (best option). Alternatively, you may read the task descriptions and the solutions (and try to understand them).</p>
<h3 data-number="7.6.1" id="sec:association_ex1"><span class="header-section-number">7.6.1</span> Exercise 1</h3>
<p>The <code>RDatasets</code> package mentioned in Section <a href="./association_corr_pitfalls.html#sec:association_corr_pitfalls">7.5</a> contains a lot of interesting data. For instance the <a href="https://vincentarelbundock.github.io/Rdatasets/doc/MASS/Animals.html">Animals</a> data frame.</p>
<pre class="language-julia"><code>animals = RD.dataset(&quot;MASS&quot;, &quot;Animals&quot;)
first(animals, 5)
</code></pre>
<div id="tbl:animalsDf">
<table>
<caption>Table 13: DataFrame for brain and body weights of 28 animal species.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Species</th>
<th style="text-align: right;">Body</th>
<th style="text-align: right;">Brain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">Mountain beaver</td>
<td style="text-align: right;">1.35</td>
<td style="text-align: right;">8.1</td>
</tr>
<tr class="even">
<td style="text-align: right;">Cow</td>
<td style="text-align: right;">465.0</td>
<td style="text-align: right;">423.0</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Grey wolf</td>
<td style="text-align: right;">36.33</td>
<td style="text-align: right;">119.5</td>
</tr>
<tr class="even">
<td style="text-align: right;">Goat</td>
<td style="text-align: right;">27.66</td>
<td style="text-align: right;">115.0</td>
</tr>
<tr class="odd">
<td style="text-align: right;">Guinea pig</td>
<td style="text-align: right;">1.04</td>
<td style="text-align: right;">5.5</td>
</tr>
</tbody>
</table>
</div>
<p>Since this chapter is all about association then we are interested to know if animal body and brain weights [kg] are correlated. Let’s take a sneak peak at the data points.</p>
<figure>
<img src="./images/ch07ex1v1.png" id="fig:ch07ex1v1" alt="Figure 31: Body and brain weight of 28 animal species." /><figcaption aria-hidden="true">Figure 31: Body and brain weight of 28 animal species.</figcaption>
</figure>
<p>Hmm, at first sight the data looks like a little mess. Most likely because of the large range of data on X- and Y-axis. Moreover, the fact that some animals like <code>Brachiosaurus</code> (<code>animals[26, :]</code>) got large body mass with relatively small brain weight doesn’t help either. Still, my impression is that in general (except for the first three points from the right) greater body weight is associated with a greater brain weight. However, it is quite hard to tell for sure as the points on the left are so close to each other on the scale of X-axis. So, let’s that to the test.</p>
<pre class="language-julia"><code>getCorAndPval(animals.Body, animals.Brain)</code></pre>
<pre class="output"><code>(-0.0053411625612511315, 0.9784802067532017)</code></pre>
<p>The Pearson’s correlation coefficient doesn’t confirm that. Nevertheless, let’s narrow our ranges by taking logarithms (with <code>log10</code> function) of the data and look at the scatter plot again.</p>
<figure>
<img src="./images/ch07ex1v2.png" id="fig:ch07ex1v2" alt="Figure 32: Body (log10) and brain (log10) weight of 28 animal species." /><figcaption aria-hidden="true">Figure 32: Body (log10) and brain (log10) weight of 28 animal species.</figcaption>
</figure>
<p>The impression we get is quite different than before, the three outliers remain, but they are are much closer to the imaginary trend line. Now we would like a way to express that relationship. One way to do it is with <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman’s rank correlation coefficient</a>. As the name implies instead of correlating the numbers themselves it correlates their ranks.</p>
<p>So here is a warm up task for you.</p>
<p>Write a <code>getSpearmCorAndPval</code> function and run it on <code>animals</code> data frame. To do that first you will need a function <code>getRanks(v::Vector{&lt;:Real})::Vector{&lt;:Float64}</code> that returns the ranks for you like this.</p>
<pre>
getRanks([500, 100, 1000]) # returns [2.0, 1.0, 3.0]
getRanks([500, 100, 500, 1000]) # returns [2.5, 1.0, 2.5, 4.0]
getRanks([500, 100, 500, 1000, 500]) # returns [3.0, 1.0, 3.0, 5.0, 3.0]
# etc.
</pre>
<p>Personally, I found <a href="https://docs.julialang.org/en/v1/base/arrays/#Base.findall-Tuple%7BFunction,%20Any%7D">findall</a> and <a href="https://docs.julialang.org/en/v1/base/sort/#Base.sort">sort</a> to be useful while writing <code>getRanks</code>, but feel free to employ whatever constructs you want. Anyway, once you got it, you can apply it to get Spearman’s correlation coefficient (<code>getCorAndPval(getRanks(v1), getRanks(v2))</code>).</p>
<blockquote>
<p><strong><em>Note:</em></strong> In real life to calculate the coefficient you would probably use <a href="https://juliastats.org/StatsBase.jl/stable/ranking/#StatsBase.corspearman">StatsBase.corspearman</a>.</p>
</blockquote>
<h3 data-number="7.6.2" id="sec:association_ex2"><span class="header-section-number">7.6.2</span> Exercise 2</h3>
<p>P-value multiplicity correction, a classic theme in this book. Let’s revisit it again. Take a look at the following data frame.</p>
<pre class="language-julia"><code>Rand.seed!(321)

letters = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;, &quot;j&quot;]
bogusCors = Dfs.DataFrame(
    Dict(l =&gt; Rand.rand(Dsts.Normal(100, 15), 10) for l in letters)
)
bogusCors[1:3, 1:3]
</code></pre>
<div id="tbl:boguscorsDf">
<table>
<caption>Table 14: DataFrame with random variables for bogus correlations.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">a</th>
<th style="text-align: right;">b</th>
<th style="text-align: right;">c</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">102.04452249090404</td>
<td style="text-align: right;">126.62114430860125</td>
<td style="text-align: right;">72.58784224875757</td>
</tr>
<tr class="even">
<td style="text-align: right;">81.10997573989799</td>
<td style="text-align: right;">101.02869856127887</td>
<td style="text-align: right;">123.65904493232378</td>
</tr>
<tr class="odd">
<td style="text-align: right;">85.54321961150684</td>
<td style="text-align: right;">109.98477666117208</td>
<td style="text-align: right;">132.32635179854458</td>
</tr>
</tbody>
</table>
</div>
<p>It contains a random made up data. In total we can calculate <code>binomial(10, 2)</code> = 45 different correlations for the 10 columns we got here. Out of them roughly 2-3 (<code>binomial(10, 2) * 0.05</code> = 2.25) would appear to be valid correlations (p &lt; 0.05), but in reality were the false positives (since we know that each column is a random variable obtained from the same distribution). So here is a task for you. Write a function that will return all the possible correlations (coefficients and p-values). Check how many of them are false positives. Apply a multiplicity correction (e.g. <code>Mt.BenjaminiHochberg()</code> we met in Section <a href="./compare_contin_data_multip_correction.html#sec:compare_contin_data_multip_correction">5.6</a>) to the p-values and check if the number of false positives drops to zero.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./association_corr_pitfalls.html"><b>7.5</b> Correlation Pitfalls</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="./association_exercises_solutions.html"><b>7.7</b> Solutions - Association</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>