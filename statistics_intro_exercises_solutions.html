<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Statistics intro - Solutions - Romeo and Julia, where Romeo is Basic Statistics</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia, where Romeo is Basic Statistics</a>
</div><br />
<span class="books-subtitle">

</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises_solutions.html"><b>5.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_imports.html"><b>6.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_flashback.html"><b>6.2</b> Flashback</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_chisq_test.html"><b>6.3</b> Chi squared test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_fisher_exact_text.html"><b>6.4</b> Fisher’s exact test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_bigger_table.html"><b>6.5</b> Bigger table</a></li>
<li><a class="menu-level-2" href="./compare_categ_test_for_independence.html"><b>6.6</b> Test for independence</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises.html"><b>6.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises_solutions.html"><b>6.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./association.html"><b>7</b> Association</a></li>
<li><a class="menu-level-2" href="./association_data_imports.html"><b>7.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./association_lin_relation.html"><b>7.2</b> Linear relation</a></li>
<li><a class="menu-level-2" href="./association_covariance.html"><b>7.3</b> Covariance</a></li>
<li><a class="menu-level-2" href="./association_correlation.html"><b>7.4</b> Correlation</a></li>
<li><a class="menu-level-2" href="./association_corr_pitfalls.html"><b>7.5</b> Correlation Pitfalls</a></li>
<li><a class="menu-level-2" href="./association_exercises.html"><b>7.6</b> Exercises - Association</a></li>
<li><a class="menu-level-2" href="./association_exercises_solutions.html"><b>7.7</b> Solutions - Association</a></li>
<li><a class="menu-level-1" href="./prediction.html"><b>8</b> Prediction</a></li>
<li><a class="menu-level-2" href="./pred_data_imports.html"><b>8.1</b> Chapter imports</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>9</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="4.9" id="sec:statistics_intro_exercises_solutions"><span class="header-section-number">4.9</span> Statistics intro - Solutions</h2>
<p>In this sub-chapter you will find exemplary solutions to the exercises from the previous section.</p>
<h3 data-number="4.9.1" id="sec:statistics_intro_exercise1_solution"><span class="header-section-number">4.9.1</span> Solution to Exercise 1</h3>
<p>The easiest way to solve this problem is to reduce it to a simpler one.</p>
<p>If the PIN number were only 1-digit, then the total number of possibilities would be equal to 10 (numbers from 0 to 9).</p>
<p>For a 2-digit PIN the pattern would be as follow:</p>
<pre>
00
01
02
...
09
10
11
12
...
19
20
21
...
98
99
</pre>
<p>So, for every number in the first location there are 10 numbers (0-9) in the second location. Therefore in total we got numbers in the range 00-99, or to write it mathematically 10 * 10 different numbers (numbers per pos. 1 * numbers per pos. 2).</p>
<p>By extension the total number of possibilities for a 4-digit PIN is:</p>
<pre class="language-julia"><code># (method1, method2, method3)
(10 * 10 * 10 * 10, 10^4, length(0:9999))</code></pre>
<pre class="output"><code>(10000, 10000, 10000)</code></pre>
<p>So 10’000 numbers. Therefore the probability for a random number being the right one is <code>1/10_000</code> = 0.0001</p>
<p>Similar methodology is used to assess the strength of a password to an internet website.</p>
<h3 data-number="4.9.2" id="sec:statistics_intro_exercise2_solution"><span class="header-section-number">4.9.2</span> Solution to Exercise 2</h3>
<p>OK, so let’s reduce the problem before we solve it.</p>
<p>If I had only 1 beer and 1 label then there is only one way to do it. The label in my hand goes to the beer in front of me.</p>
<p>For 2 labels and 2 beer it goes like this:</p>
<pre>
a b
b a
</pre>
<p>I place one of two labels on a first beer, and I’m left with only 1 label for the second beer. So, 2 possibilities in total.</p>
<p>For 3 labels and 3 beer the possibilities are as follow:</p>
<pre>
a b c
a c b

b a c
b c a

c a b
c b a
</pre>
<p>So here, for the first beer I can assign any of the three labels (<code>a</code>, <code>b</code>, or <code>c</code>). Then I move to the second beer and have only two labels left in my hand (if the first got <code>a</code>, then the second can get only <code>b</code> or <code>c</code>). Then I move to the last beer with the last label in my hand (if the first two were <code>a</code> and <code>b</code> then I’m left with <code>c</code>). In total I got <code>3 * 2 * 1</code> = 6 possibilities.</p>
<p>It turns out this relationship holds also for bigger numbers. In mathematics it can be calculated using <a href="https://en.wikipedia.org/wiki/Factorial">factorial</a> function that is already implemented in Julia (see <a href="https://docs.julialang.org/en/v1/base/math/#Base.factorial">the docs</a>).</p>
<p>Still, for practice we’re gonna implement one on our own with the <code>foreach</code> we met in Section <a href="./julia_language_repetition.html#sec:julia_language_map_foreach">3.6.4</a>.</p>
<pre class="language-julia"><code>function myFactorial(n::Int)::Int
    @assert n &gt; 0 &quot;n must be positive&quot;
    product::Int = 1
    foreach(x -&gt; product *= x, 1:n)
    return product
end

myFactorial(6)</code></pre>
<p>720</p>
<blockquote>
<p><strong><em>Note:</em></strong> You may also just use Julia’s <a href="https://docs.julialang.org/en/v1/base/collections/#Base.prod">prod</a> function, e.g. <code>prod(1:6)</code> = 720. Still, be aware that factorial numbers grow pretty fast, so for bigger numbers, e.g. <code>myFactorial(20)</code> or above you might want to change the definition of <code>myFactorial</code> to use <code>BigInt</code> that we met in Section <a href="./julia_language_exercises_solutions.html#sec:julia_language_exercise5_solution">3.9.5</a>.</p>
</blockquote>
<p>So, the probability that a person correctly labels 6 beer at random is <code>round(1/factorial(6), digits=5)</code> = 0.00139.</p>
<p>I guess that is the reason why out of 7 people that attempted to correctly label 6 beer the results were as follows:</p>
<ul>
<li>one person correctly labeled 0 beer</li>
<li>five people correctly labeled 1 beer</li>
<li>one person correctly labeled 2 beer</li>
</ul>
<p>I leave the conclusions to you.</p>
<h3 data-number="4.9.3" id="sec:statistics_intro_exercise3_solution"><span class="header-section-number">4.9.3</span> Solution to Exercise 3</h3>
<p>OK, for the original tennis example (see Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_tennis">4.7.1</a>) we answered the question by using a computer simulation first (Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_tennis_comp_simul">4.7.2</a>). For a change, this time we will start with a ‘purely mathematical’ calculations. Ready?</p>
<p>In order to get the result of 1-5 for Peter we would have to get a series of games like this one:</p>
<pre>
# 0 - John's victory, 1 - Peter's victory
0 1 1 1 1 1
</pre>
<p>Probability of either John or Peter winning under <span class="math inline">\(H_{0}\)</span> (assumption that they play equally well) is <span class="math inline">\(\frac{1}{2}\)</span> = 0.5. So here we got a conjunction of probabilities (John won AND Peter won AND Peter won AND …). According to what we’ve learned in Section <a href="./statistics_intro_probability_properties.html#sec:statistics_intro_probability_summary">4.3.1</a> we should multiply the probabilities by each other.</p>
<p>Therefore, the probability of the result above is <code>0.5 * 0.5 * 0.5 * ...</code> or <code>0.5 ^ 6</code> = 0.015625. But wait, there’s more. We can get such a result (1-5 for Peter) in a few different ways, i.e.</p>
<pre>
0 1 1 1 1 1
# or
1 0 1 1 1 1
# or
1 1 0 1 1 1
# or
1 1 1 0 1 1
# or
1 1 1 1 0 1
# or
1 1 1 1 1 0
</pre>
<blockquote>
<p><strong><em>Note:</em></strong> For a big number of games it is tedious and boring to write all the possibilities by hand. In this case you may use Julia’s <a href="https://docs.julialang.org/en/v1/base/math/#Base.binomial">binomial</a> funcion, e.g. <code>binomial(6, 5)</code> = 6. This tells us how many different fives of six objects can we get.</p>
</blockquote>
<p>As we said a moment ago, each of this series of games occurs with the probability of 0.015625. Since we used OR (see the coments in the code above) then according to Section <a href="./statistics_intro_probability_properties.html#sec:statistics_intro_probability_summary">4.3.1</a> we can add 0.015625 six times to itself (or multiply it by 6). So, the probability is equal to:</p>
<pre class="language-julia"><code>prob1to5 = (0.5^6) * 6 # parenthesis were placed for the sake of clarity
prob1to5</code></pre>
<p>0.09375</p>
<p>Of course we must remember what our imaginary statistician said in Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_tennis">4.7.1</a>: “I assume that <span class="math inline">\(H_{0}\)</span> is true. Then I will conduct the experiment and record then result. I will calculate the probability of such a result (or more extreme result) happening by chance.”</p>
<p><code>More extreme</code> than 1-5 for Peter is 0-6 for Peter, we previously (see Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_tennis_theor_calc">4.7.3</a>) calculated it to be <code>0.5^6</code> = 0.015625. Finally, we can get our p-value (for one-tailed test)</p>
<pre class="language-julia"><code>prob1to5 = (0.5^6) * 6 # parenthesis were placed for the sake of clarity
prob0to6 = 0.5^6
probBothOneTail = prob1to5 + prob0to6

probBothOneTail</code></pre>
<p>0.109375</p>
<blockquote>
<p><strong><em>Note:</em></strong> Once you get used to calculating probabilities you should use quick methods like those from <code>Distributions</code> package (presented below), but for now it is important to understand what happens here, hence those long calculations (of <code>probBothOneTail</code>) presented here.</p>
</blockquote>
<p>Let’s quickly verify it with other methods we met before (e.g. in Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_hypothesis_testing">4.7</a>)</p>
<pre class="language-julia"><code># for better clarity each method is in a separate line
(
probBothOneTail,
1 - Dsts.cdf(Dsts.Binomial(6, 0.5), 4),
Dsts.pdf.(Dsts.Binomial(6, 0.5), 5:6) |&gt; sum,
tennisProbs[5] + tennisProbs[6] # experimental probability
)</code></pre>
<pre class="output"><code>(0.109375, 0.109375, 0.10937499999999988, 0.11052000000000001)</code></pre>
<p>Yep, they all appear the same (remember about floats rounding and the difference between theory and practice from Section <a href="./statistics_prob_theor_practice.html#sec:statistics_prob_theor_practice">4.4</a>).</p>
<p>So, is it significant at the crazy cutoff level of <span class="math inline">\(\alpha = 0.15\)</span>?</p>
<pre class="language-julia"><code>shouldRejectH0(probBothOneTail, 0.15)</code></pre>
<p>true</p>
<p>Yes, it is (we reject <span class="math inline">\(H_{0}\)</span> on favor of <span class="math inline">\(H_{A}\)</span>). And now for the two-tailed test.</p>
<pre class="language-julia"><code># remember the probability distribution is symmetrical, so *2 is OK here
shouldRejectH0(probBothOneTail * 2, 0.15)</code></pre>
<p>false</p>
<p>Here we cannot reject our <span class="math inline">\(H_{0}\)</span>.</p>
<p>Of course we all know that this was just for practice, because the acceptable type I error cutoff level is usually 0.05 or 0.01. In this case, according to both the one-tailed and two-tailed tests we failed to reject the <span class="math inline">\(H_{0}\)</span>.</p>
<p>BTW, this shows how important it is to use a strict mathematical reasoning and to adhere to our own methodology. I don’t know about you but when I had been a student I would have probably accepted the result 1-5 for Peter as an intuitive evidence that he is a better tennis player.</p>
<p>We will see how to speed up the calculations in this solution in one of the upcoming chapters (see Section <a href="./compare_categ_data_flashback.html#sec:compare_categ_data_flashback">6.2</a>).</p>
<h3 data-number="4.9.4" id="sec:statistics_intro_exercise4_solution"><span class="header-section-number">4.9.4</span> Solution to Exercise 4</h3>
<p>OK, there maybe more than one way to solve this problem.</p>
<p><strong>Solution 4.1</strong></p>
<p>In chess, a game can end with one of three results: white win, black win or a draw. If we assume each of those options to be equally likely for two well matched chess players then the probability of each of the three results is <code>1/3</code> (this is our <span class="math inline">\(H_{0}\)</span>).</p>
<p>So, similarly to our tennis example from Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_tennis">4.7.1</a> the probability (one-tailed test) of Paul winning all six games is</p>
<pre class="language-julia"><code># (1/3) that Paul won a single game AND six games in a row (^6)
(
round((1/3)^6, digits=5),
round(Dsts.pdf(Dsts.Binomial(6, 1/3), 6), digits=5)
)</code></pre>
<pre class="output"><code>(0.00137, 0.00137)</code></pre>
<p>So, you might think right now ‘That task was a piece of cake’ and you would be right. But wait, there’s more.</p>
<p><strong>Solution 4.2</strong></p>
<p>In chess played at a top level (&gt;= 2500 ELO) the most probable outcome is draw. It occurs with a frequency of roughly 50% (see <a href="https://en.wikipedia.org/wiki/Draw_(chess)#Frequency_of_draws">this Wikipedia’s page</a>). Based on that we could assume that for two equally strong chess players the probability of:</p>
<ul>
<li>white winning is <code>1/4</code>,</li>
<li>draw is <code>2/4</code> = <code>1/2</code>,</li>
<li>black winning <code>1/4</code></li>
</ul>
<p>So under those assumptions the probability that Paul won all six games is</p>
<pre class="language-julia"><code># (1/4) that Paul won a single game AND six games in a row (^6)
(
round((1/4)^6, digits=5),
round(Dsts.pdf(Dsts.Binomial(6, 1/4), 6), digits=5)
)</code></pre>
<pre class="output"><code>(0.00024, 0.00024)</code></pre>
<p>So a bit lower, than the probability we got before (which was <code>(1/3)^6</code> = 0.00137).</p>
<p>OK, so I presented you with two possible solutions. One gave the probability of <code>(1/3)^6</code> = 0.00137, whereas the other <code>(1/4)^6</code> = 0.00024. So, which one is it, which one is the true probability? Well, probably neither. Those are both just estimations of the true probability and they are only as good as the assumptions that we make. After all: <a href="https://en.wikipedia.org/wiki/All_models_are_wrong">“All models are wrong, but some are useful”</a>.</p>
<p>If the assumptions are correct, then we can get a pretty good estimate. Both the <code>Solution 4.1</code> and <code>Solution 4.2</code> got reasonable assumptions but they are not necessarily true (e.g. I’m not a &gt;= 2500 ELO chess player). Still, for practical reasons they may be more useful than just guessing, for instance if you were ever to bet on a result of a chess game/match (do you remember the bets from Section <a href="./statistics_prob_distribution.html#sec:statistics_prob_distribution">4.5</a>?).</p>
<p>The reason I mentioned it is not for you to place bets on chess matches but to point on similarities to statistical practice.</p>
<p>For instance, there is a method named <a href="https://en.wikipedia.org/wiki/One-way_analysis_of_variance">one-way ANOVA</a> (we will discuss it in one of the upcoming chapters). Sometimes it requires to conduct a so called <a href="https://en.wikipedia.org/wiki/Post_hoc_analysis">post-hoc test</a>. There are quite a few of them to choose from (see the link above) and they rely on different assumptions. For instance one may do Fisher’s LSD test or Tukey’s HSD test. Which one to choose? I think you should choose the test that is better suited for the job (based on your knowledge and recommendations from the experts).</p>
<p>Regarding the above mentioned tests. Fisher’s LSD test was introduced by <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Ronald Fisher</a> (what a surprise). LSD stands for <strong>L</strong>east <strong>S</strong>ignificant <strong>D</strong>ifference. Some time later <a href="https://en.wikipedia.org/wiki/John_Tukey">John Tukey</a> considered it to be too lenient (too easily rejects <span class="math inline">\(H_{0}\)</span> and declares significant differences) and offered his own test (operating on different assumptions) as an alternative. For that reason it was named HSD which stands for <strong>H</strong>onestly <strong>S</strong>ignificant <strong>D</strong>ifference. I heard that statisticians recommend to use the latter one (although in practice I saw people use either of them).</p>
<h3 data-number="4.9.5" id="sec:statistics_intro_exercise5_solution"><span class="header-section-number">4.9.5</span> Solution to Exercise 5</h3>
<p>OK, so we assume that Peter is a better player than John and he consistently wins with John. On average he wins with the ratio 5 to 1 (5:1) with his opponent (this is our true <span class="math inline">\(H_{A}\)</span>). Let’s write a function that gives us the result of the experiment if this <span class="math inline">\(H_{A}\)</span> is true.</p>
<pre class="language-julia"><code>function getResultOf1TennisGameUnderHA()::Int
    # 0 - John wins, 1 - Peter wins
    return Rand.rand([0, 1, 1, 1, 1, 1], 1)
end

function getResultOf6TennisGamesUnderHA()::Int
    return [getResultOf1TennisGameUnderHA() for _ in 1:6] |&gt; sum
end</code></pre>
<p>The code is fairly simple. Let me just explain one part. Under <span class="math inline">\(H_{A}\)</span> Peter wins 5 out of six games and John 1 out of 6, therefore we choose one number out of <code>[0, 1, 1, 1, 1, 1]</code> (0 - John wins, 1 - Peter wins) with our <code>Rand.rand([0, 1, 1, 1, 1, 1], 1)</code>.</p>
<blockquote>
<p><strong><em>Note:</em></strong> If the <span class="math inline">\(H_{A}\)</span> would be let’s say 1:99 for Peter, then to save you some typing I would recommend to do something like, e.g. <code>return (Rand.rand(1:100, 1) &lt; 100) ? 1 : 0</code>. It draws one random number out of 100 numbers. If the number is 1-99 then it returns 1 (Peter wins) else it returns 0 (John wins). BTW. When a probability of an event is small (e.g. <span class="math inline">\(\le\)</span> 1%) then to get its more accurate extimate you could/should increase the number of computer simulations (e.g. <code>numOfSimul</code> below should be <code>1_000_000</code> instead of <code>100_000</code>).</p>
</blockquote>
<p>Alternatively the code from the snippet above could be shortened to</p>
<pre class="language-julia"><code># here no getResultOf1TennisGameUnderHA is needed
function getResultOf6TennisGamesUnderHA()::Int
    return Rand.rand([0, 1, 1, 1, 1, 1], 6) |&gt; sum
end</code></pre>
<p>Now let’s run the experiment, let’s say <code>100_000</code> times, and see how many times we will fail to reject <span class="math inline">\(H_{0}\)</span>. For that we will need the following helper functions</p>
<pre class="language-julia"><code>function play6tennisGamesGetPvalue()::Float64
    # result when HA is true
    result::Int = getResultOf6TennisGamesUnderHA()
    # probability based on which we may decide to reject H0
    oneTailPval::Float64 = Dsts.pdf.(Dsts.Binomial(6, 0.5), result:6) |&gt; sum
    return oneTailPval
end

function didFailToRejectHO(pVal::Float64)::Bool
    return pVal &gt; 0.05
end</code></pre>
<p>In <code>play6tennisGamesGetPvalue</code> we conduct an experiment and get a p-value (probability of type 1 error). First we get the result of the experiment under <span class="math inline">\(H_{A}\)</span>, i.e we assume the true probability of Peter winning a game with John to be <code>5/6</code> = 0.8333. We assign the result of those 6 games to a variable <code>result</code>. Next we calculate the probability of obtaining such a result by chance under <span class="math inline">\(H_{0}\)</span>, i.e. probability of Peter winning is <code>1/2</code> = 0.5 as we did in Section <a href="./statistics_intro_exercises_solutions.html#sec:statistics_intro_exercise3_solution">4.9.3</a>. We return that probability.</p>
<p>Previously we said that the accepted cutoff level for alpha is 0.05 (see Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_cutoff_levels">4.7.6</a>). If p-value <span class="math inline">\(\le\)</span> 0.05 we reject <span class="math inline">\(H_{0}\)</span> and choose <span class="math inline">\(H_{A}\)</span>. Here for <span class="math inline">\(\beta\)</span> we need to know whether we fail to reject <span class="math inline">\(H_{0}\)</span> hence <code>didFailToRejectHO</code> function with <code>pVal &gt; 0.05</code>.</p>
<p>And now, we can go to the promised <code>100_000</code> simulations.</p>
<pre class="language-julia"><code>numOfSimul = 100_000
Rand.seed!(321)
notRejectedH0 = [
    didFailToRejectHO(play6tennisGamesGetPvalue()) for _ in 1:numOfSimul
    ]
probOfType2error = sum(notRejectedH0) / length(notRejectedH0)</code></pre>
<p>0.66384</p>
<p>We run our experiment <code>100_000</code> times and record whether we failed to reject <span class="math inline">\(H_{0}\)</span>. We put that to <code>notRejectedH0</code> using comprehensions (see Section <a href="./julia_language_repetition.html#sec:julia_language_comprehensions">3.6.3</a>). We get a vector of <code>Bool</code>s (e.g. <code>[true, false, true]</code>). When used with <code>sum</code> function Julia treats <code>true</code> as <code>1</code> and <code>false</code> as <code>0</code>. We can use that to get the average of <code>true</code> (fraction of times we failed to reject <span class="math inline">\(H_{0}\)</span>). This is the probability of type II error, it is equal to 0.66384. We can use it to calculate the power of a test (power = 1 - β).</p>
<pre class="language-julia"><code>function getPower(beta::Float64)::Float64
    @assert (0 &lt;= beta &lt;= 1) &quot;beta must be in range [0-1]&quot;
    return 1 - beta
end
powerOfTest = getPower(probOfType2error)

powerOfTest</code></pre>
<p>0.33616</p>
<p>Finally we get our results. We can compare them with the cutoff values from Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_cutoff_levels">4.7.6</a>, e.g. <span class="math inline">\(\beta \le 0.2\)</span>, <span class="math inline">\(power \ge 0.8\)</span>. So it turns out that if in reality Peter is a better tennis player than John (and on average wins with the ratio 5:1) then we will be able to confirm that rougly in 3 experiments out of 10 (experiment - the result of 6 games that they play with each other). This is because the power of a test should be <span class="math inline">\(\ge\)</span> 0.8 (accepted by statisticians), but it is 0.33616 (estimated in our computer simulation). Here we can either say that they both (John and Peter) play equally well (we did not reject <span class="math inline">\(H_{0}\)</span>) or make them play a greater number of games with each other in order to confirm that Peter consistently wins with John with the average ratio of 5 to 1.</p>
<p>If you want to see a graphical representation of the solution to exercise 5 take a look at the figure below.</p>
<figure>
<img src="./images/tennisBetaExample.png" id="fig:tennisBetaExample" alt="Figure 10: Graphical representation of estimation process for type II error and the power of a test." /><figcaption aria-hidden="true">Figure 10: Graphical representation of estimation process for type II error and the power of a test.</figcaption>
</figure>
<p>The top panels display the probability distributions for our experiment (6 games of tennis) under <span class="math inline">\(H_{0}\)</span> (red bars) and <span class="math inline">\(H_{A}\)</span> (blue bars). Notice, that the blue bars for 0, 1, and 2 are so small that they are barely (or not at all) visible on the graph. The black dotted vertical line is a cutoff level for type I error (or <span class="math inline">\(\alpha\)</span>), which is 0.05. The bottom panel contains the distributions superimposed one on the other. The probability of type II error (or <span class="math inline">\(\beta\)</span>) is the sum of the heights of the blue bar(s) to the left from the black dotted vertical line (the cutoff level for type I error). The power of a test is the sum of the heights of the blue bar(s) to the right from the black dotted vertical line (the cutoff level for type I error).</p>
<p>Hopefully the explanations above were clear enough. Still, the presented solution got a few flaws, i.e. we hard coded 6 into our functions (e.g. <code>getResultOf1TennisGameUnderHA</code>, <code>play6tennisGamesGetPvalue</code>), moreover running <code>100_000</code> simulations is probably less efficient than running purely mathematical calculations. Let’s try to add some plasticity and efficiency to our code (plus let’s check the accuracy of our computer simulation).</p>
<pre class="language-julia"><code># to the right from that point on x-axis (&gt;point) we reject H0 and choose HA
# n - number of trials (games)
function getXForBinomRightTailProb(n::Int, probH0::Float64,
                                   rightTailProb::Float64)::Int
    @assert (0 &lt;= rightTailProb &lt;= 1) &quot;rightTailProb must be in range [0-1]&quot;
    @assert (0 &lt;= probH0 &lt;= 1) &quot;probH0 must be in range [0-1]&quot;
    @assert (n &gt; 0) &quot;n must be positive&quot;
    return Dsts.cquantile(Dsts.Binomial(n, probH0), rightTailProb)
end

# n - number of trials (games), x - number of successes (Peter&#39;s wins)
# returns probability (under HA) from far left upto (and including) x
function getBetaForBinomialHA(n::Int, x::Int, probHA::Float64)::Float64
    @assert (0 &lt;= probHA &lt;= 1) &quot;probHA must be in range [0-1]&quot;
    @assert (n &gt; 0) &quot;n must be positive&quot;
    @assert (x &gt;= 0) &quot;x musn&#39;t be negative&quot;
    return Dsts.cdf(Dsts.Binomial(n, probHA), x)
end</code></pre>
<blockquote>
<p><strong><em>Note:</em></strong> The above functions should work correctly if probH0 &lt; probHA, i.e. the probability distribution under <span class="math inline">\(H_{0}\)</span> is on the left and the probability distribution under <span class="math inline">\(H_{A}\)</span> is on the right side, i.e. the case you see in Figure <a href="#fig:tennisBetaExample">10</a>.</p>
</blockquote>
<p>The function <code>getXForBinomRightTailProb</code> returns a value (number of Peter’s wins, number of successes, value on x-axis in Figure <a href="#fig:tennisBetaExample">10</a>) above which we reject <span class="math inline">\(H_{0}\)</span> in favor of <span class="math inline">\(H_{A}\)</span> (if we feed it with cutoff for <span class="math inline">\(\alpha\)</span> equal to 0.05). Take a look at Figure <a href="#fig:tennisBetaExample">10</a>, it returns the value on x-axis to the right of which the sum of heights of the red bars is lower than the cutoff level for alpha (type I error). It does so by wrapping around <a href="https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.cquantile-Tuple%7BUnivariateDistribution,%20Real%7D">Dsts.cquantile</a> function (that runs the necessary mathematical calculations) for us.</p>
<p>Once we get this cutoff point (number of successes, here number of Peter’s wins) we can feed it as an input to <code>getBetaForBinomialHA</code>. Again, take a look at Figure <a href="#fig:tennisBetaExample">10</a>, it calculates for us the sum of the heights of the blue bars from the far left (0 on x-axis) up-to the previously obtained cutoff point (the height of that bar is also included). Let’s see how it works in practice.</p>
<pre class="language-julia"><code>xCutoff = getXForBinomRightTailProb(6, 0.5, 0.05)
probOfType2error2 = getBetaForBinomialHA(6, xCutoff, 5/6)
powerOfTest2 = getPower(probOfType2error2)

(probOfType2error, probOfType2error2, powerOfTest, powerOfTest2)</code></pre>
<pre class="output"><code>(0.66384, 0.6651020233196159, 0.33616, 0.3348979766803841)</code></pre>
<p>They appear to be close enough which indicates that our calculations with the computer simulation were correct.</p>
<hr />
<p><strong>Bonus. Sample size estimation.</strong></p>
<p>As a bonus to this exerise let’s talk about sample sizes.</p>
<p>Notice that after solving this exercise we said that if Peter is actually a better player than John and wins on average 5:1 with his opponent then still, most likely we will not be able to show this with 6 tennis games (<code>powerOfTest2</code> = 0.3349). So, if ten such experiments would be conducted around the world for similar Peters and Johns then roughly only in three of them Peter would be declared a better player after running statistical tests. That doesn’t sound right.</p>
<p>In order to overcome this at the onset of their experiment a statistician should also try to determine the proper sample size. First, he starts by asking himself a question: “how big difference will make a difference.” This is an arbitrary decision (at least a bit). Still, I think we can all agree that if Peter would win with John on average 99:1 then this would make a practical difference (probably John would not like to play with him, what’s the point if he would be still loosing). OK, and how about Peter wins with John on average 51:49. This does not make a practical difference. Here they are pretty well matched and would play with each other since it would be challenging enough for both of them and each one could win a decent amount of games to remain satisfied. Most likely, they would be even unaware of such a small difference.</p>
<p>In real life a physician could say, e.g. “I’m going to test a new drug that should reduce the level of ‘bad cholesterol’ (<a href="https://en.wikipedia.org/wiki/Low-density_lipoprotein">LDL-C</a>). How big reduction would I like to detect? Hmm, I know, 30 [mg/dL] or more because it reduces the risk of a heart attack by 50%” or “By at least 25 [mg/dL] because the drug that is already on the market reduces it by 25 [mg/dL]” (the numbers were made up by me, I’m not a physician).</p>
<p>Anyway, once a statistician gets the difference that makes a difference he tries to estimate the sample size by making some reasonable assumptions about rest of the parameters.</p>
<p>In our tennis example we could write the following function for sample size estimation</p>
<pre class="language-julia"><code># checks sample sizes between start and finish (inclusive, inclusive)
# assumes that probH0 is 0.5
function getSampleSizeBinomial(probHA::Float64,
    cutoffBeta::Float64=0.2,
    cutoffAlpha::Float64=0.05,
    twoTail::Bool=true,
    start::Int=6, finish::Int=40)::Int

    # other probs are asserted in the component functions that use them
    @assert (0 &lt;= cutoffBeta &lt;= 1) &quot;cutoffBeta must be in range [0-1]&quot;
    @assert (start &gt; 0 &amp;&amp; finish &gt; 0) &quot;start and finish must be positive&quot;
    @assert (start &lt; finish) &quot;start must be smaller than finish&quot;

    probH0::Float64 = 0.5
    sampleSize::Int = -99
    xCutoffForAlpha::Int = 0
    beta::Float64 = 1.0

    if probH0 &gt;= probHA
        probHA = 1 - probHA
    end
    if twoTail
        cutoffAlpha = cutoffAlpha / 2
    end

    for n in start:finish
        xCutoffForAlpha = getXForBinomRightTailProb(n, probH0, cutoffAlpha)
        beta = getBetaForBinomialHA(n, xCutoffForAlpha, probHA)
        if beta &lt;= cutoffBeta
            sampleSize = n
            break
        end
    end

    return sampleSize
end</code></pre>
<p>That is not the most efficient method, but it should do the trick.</p>
<p>First, we initialize a few variables that we will use later (<code>probH0</code>, <code>sampleSize</code>, <code>xCutoffForAlpha</code>, <code>beta</code>). Then we compare <code>probH0</code> with <code>probHA</code>. We do this since <code>getXForBinomRightTailProb</code> and <code>getBetaForBinomialHA</code> should work correctly only when <code>probH0</code> &lt; <code>probHA</code> (see the note under the code snippet with the functions definitions). Therefore we need to deal with the case when it is otherwise (<code>if probH0 &gt; probHA</code>). We do this by subtracting <code>probHA</code> from 1 and making it our new <code>probHA</code> (<code>probHA = 1 - probHA</code>). Because of that if we ever type, e.g. <code>probHA</code> = 1/6 = 0.166, then the function will transform it to <code>probHA</code> = 1 - 1/6 = 5/6 = 0.833 (since in our case the sample size required to demonstrate that Peter wins on average 1 out of 6 games, is the same as the sample size required to show that John wins on average 5 out of 6 games).</p>
<p>Once we are done with that we go to another checkup. If we are interested in two-tailed probability (<code>cutoffAlpha</code> = 0.05) then we divide the number (<code>cutoffAlpha</code>) by two. Before 0.05 went to the right side (see the black dotted line in Figure <a href="#fig:tennisBetaExample">10</a>), now we split it, 0.025 goes to the left side, 0.025 goes to the right side of the probability distribution. This makes sense since before (see Section <a href="./statistics_intro_hypothesis_testing.html#sec:statistics_intro_one_or_two_tails">4.7.4</a>) we multiplied one-tailed probability by 2 to get the two-tailed probability, here we do the opposite. We can do that because the probability distribution under <span class="math inline">\(H_{0}\)</span> (see upper left panel in Figure <a href="#fig:tennisBetaExample">10</a>) is symmetrical.</p>
<p>Finally, we use the previously defined functions (<code>getXForBinomRightTailProb</code> and <code>getBetaForBinomialHA</code>) and conduct a series of experiments for different sample sizes (between <code>start</code> and <code>finish</code>). Once the obtained <code>beta</code> fulfills the requirement (<code>beta &lt;= cutoffBeta</code>) we set <code>sampleSize</code> to that value (<code>sampleSize = n</code>) and stop subsequent search with a <code>break</code> statement (so if <code>sampleSize</code> of 6 is OK, we will not look at larger sample sizes). If the <code>for</code> loop terminates without satisfying our requirements then the value of <code>-99</code> (<code>sampleSize</code> was initialized with it) is returned. This is an impossible value for a sample size. Therefore it points out that the search failed. Let’s put it to the test.</p>
<p>In this exercise we said that Peter wins with John on average 5:1 (<span class="math inline">\(H_{A}\)</span>, prob = 5/6 = 0.83). So what is the sample size necessary to confirm that with the acceptable type I error (<span class="math inline">\(alpha \le 0.05\)</span>) and type II error (<span class="math inline">\(\beta \le 0.2\)</span>) cutoffs.</p>
<pre class="language-julia"><code># for one-tailed test
sampleSizeHA5to1 = getSampleSizeBinomial(5/6, 0.2, 0.05, false)
sampleSizeHA5to1</code></pre>
<p>13</p>
<p>OK, so in order to be able to detect such a big difference (5:1, or even bigger) between the two tennis players they would have to play 13 games with each other (for one-tailed test). To put it into perspective and compare it with Figure <a href="#fig:tennisBetaExample">10</a> look at the graph below.</p>
<figure>
<img src="./images/tennisBetaExampleN13.png" id="fig:tennisBetaExampleN13" alt="Figure 11: Graphical representation of type II error and the power of a test for 13 tennis games between Peter and John." /><figcaption aria-hidden="true">Figure 11: Graphical representation of type II error and the power of a test for 13 tennis games between Peter and John.</figcaption>
</figure>
<p>If our function worked well then the sum of the heights of the blue bars to the right of the black dotted line should be <span class="math inline">\(\ge 0.8\)</span> (power of the test) and to the left should be <span class="math inline">\(\le 0.2\)</span> (type II error or <span class="math inline">\(\beta\)</span>).</p>
<pre class="language-julia"><code>(
# alternative to the line below: 1 - Dsts.cdf(Dsts.Binomial(13, 5/6), 9),
Dsts.pdf.(Dsts.Binomial(13, 5/6), 10:13) |&gt; sum,
Dsts.cdf(Dsts.Binomial(13, 5/6), 9)
)</code></pre>
<pre class="output"><code>(0.841922621916511, 0.15807737808348934)</code></pre>
<p>Yep, that’s correct. So, under those assumptions in order to confirm that Peter is a better tennis player he would have to win <span class="math inline">\(\ge 10\)</span> games out of 13.</p>
<p>And how about the two-tailed probability (we expect the number of games to be greater).</p>
<pre class="language-julia"><code># for two-tailed test
getSampleSizeBinomial(5/6, 0.2, 0.05)</code></pre>
<p>17</p>
<p>Here we need 17 games to be sufficiently sure we can prove Peter’s supremacy.</p>
<p>OK. Let’s give our <code>getSampleSizeBinomial</code> one more swing. How about if Peter wins with John on average 4:2 (<span class="math inline">\(H_{A}\)</span>)?</p>
<pre class="language-julia"><code># for two-tailed test
sampleSizeHA4to2 = getSampleSizeBinomial(4/6, 0.2, 0.05)
sampleSizeHA4to2</code></pre>
<p>-99</p>
<p>Hmm, <code>-99</code>, so it will take more than 40 games (<code>finish::Int = 40</code>). Now, we can either stop here (since playing 40 games in a row is too time and energy consuming so we resign) or increase the value for <code>finish</code> like so</p>
<pre class="language-julia"><code># for two-tailed test
sampleSizeHA4to2 = getSampleSizeBinomial(4/6, 0.2, 0.05, true, 6, 100)
sampleSizeHA4to2</code></pre>
<p>72</p>
<p>Wow, if Peter is better than John in tennis and on average wins 4:2 then it would take 72 games to be sufficiently sure to prove it (who would have thought).</p>
<p>Anyway, if you ever find yourself in need to determine sample size, <span class="math inline">\(\beta\)</span> or the power of a test (not only for one-sided tests as we did here) then you should probably consider using <a href="https://github.com/rikhuijzer/PowerAnalyses.jl">PowerAnalyses.jl</a> which is on <a href="https://en.wikipedia.org/wiki/MIT_License">MIT</a> license.</p>
<p>OK, I think you deserve some rest before moving to the next chapter so why won’t you take it now.</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>