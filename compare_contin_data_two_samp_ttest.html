<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Bartlomiej Lukaszuk" />
  <title>Two samples Student’s t-test - Romeo and Julia, where Romeo is Basic Statistics</title>
  <link rel="stylesheet" href="./style.css"/>
    <script src="./mousetrap.min.js"></script>
    <style>
  @font-face {
    font-family: JuliaMono-Regular;
    src: url("./JuliaMono-Regular.woff2");
  }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link rel="stylesheet" href="./github.min.css">
<script src="./highlight.min.js"></script>
<script src="./julia.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', (event) => {
    document.querySelectorAll('pre').forEach((el) => {
        if (!el.classList.contains('output')) {
            hljs.highlightElement(el);
        }
    });
});
</script>
 
</head>
<body>
<script>
function click_next() {
  var next = document.getElementById('nav-next');
  next.firstElementChild.nextElementSibling.click();
}
function click_prev() {
  var prev = document.getElementById('nav-prev');
  prev.firstElementChild.click();
}
Mousetrap.bind('right', click_next);
Mousetrap.bind('h', click_prev);
Mousetrap.bind('left', click_prev);
Mousetrap.bind('l', click_next);
</script>

<div class="books-container">
<aside class="books-menu">
<input type="checkbox" id="menu">
<label for="menu">☰</label>
<div class="books-title">
<a href="./">Romeo and Julia, where Romeo is Basic Statistics</a>
</div><br />
<span class="books-subtitle">

</span>
<div class="books-menu-content">
<li><a class="menu-level-1" href="./about.html"><b>1</b> About</a></li>
<li><a class="menu-level-1" href="./why_julia.html"><b>2</b> Why Julia</a></li>
<li><a class="menu-level-2" href="./julia_is_fast.html"><b>2.1</b> Julia is fast</a></li>
<li><a class="menu-level-2" href="./julia_is_simple.html"><b>2.2</b> Julia is simple</a></li>
<li><a class="menu-level-2" href="./jl_pleasure_to_write.html"><b>2.3</b> Pleasure to write</a></li>
<li><a class="menu-level-2" href="./jl_not_mainstream.html"><b>2.4</b> Not mainstream</a></li>
<li><a class="menu-level-2" href="./jl_open_source.html"><b>2.5</b> Julia is free</a></li>
<li><a class="menu-level-1" href="./julia_first_encounter.html"><b>3</b> Julia - first encounter</a></li>
<li><a class="menu-level-2" href="./julia_installation.html"><b>3.1</b> Installation</a></li>
<li><a class="menu-level-2" href="./julia_language_constructs.html"><b>3.2</b> Language Constructs</a></li>
<li><a class="menu-level-2" href="./julia_language_variables.html"><b>3.3</b> Variables</a></li>
<li><a class="menu-level-2" href="./julia_language_functions.html"><b>3.4</b> Functions</a></li>
<li><a class="menu-level-2" href="./julia_language_decision_making.html"><b>3.5</b> Decision Making</a></li>
<li><a class="menu-level-2" href="./julia_language_repetition.html"><b>3.6</b> Repetition</a></li>
<li><a class="menu-level-2" href="./julia_language_libraries.html"><b>3.7</b> Additional libraries</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises.html"><b>3.8</b> Julia - Exercises</a></li>
<li><a class="menu-level-2" href="./julia_language_exercises_solutions.html"><b>3.9</b> Julia - Solutions</a></li>
<li><a class="menu-level-1" href="./statistics_intro.html"><b>4</b> Statistics - introduction</a></li>
<li><a class="menu-level-2" href="./statistics_intro_imports.html"><b>4.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_definition.html"><b>4.2</b> Probability - definition</a></li>
<li><a class="menu-level-2" href="./statistics_intro_probability_properties.html"><b>4.3</b> Probability - properties</a></li>
<li><a class="menu-level-2" href="./statistics_prob_theor_practice.html"><b>4.4</b> Probability - theory and..</a></li>
<li><a class="menu-level-2" href="./statistics_prob_distribution.html"><b>4.5</b> Probability distribution</a></li>
<li><a class="menu-level-2" href="./statistics_normal_distribution.html"><b>4.6</b> Normal distribution</a></li>
<li><a class="menu-level-2" href="./statistics_intro_hypothesis_testing.html"><b>4.7</b> Hypothesis testing</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises.html"><b>4.8</b> Statistics intro - Exerc..</a></li>
<li><a class="menu-level-2" href="./statistics_intro_exercises_solutions.html"><b>4.9</b> Statistics intro - Solut..</a></li>
<li><a class="menu-level-1" href="./compare_contin_data.html"><b>5</b> Comparisons - continuous d..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_imports.html"><b>5.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_two_samp_ttest.html"><b>5.3</b> Two samples Student’s ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_post_hoc_tests.html"><b>5.5</b> Post-hoc tests</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_multip_correction.html"><b>5.6</b> Multiplicity correction</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises.html"><b>5.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_contin_data_exercises_solutions.html"><b>5.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./compare_categ_data.html"><b>6</b> Comparisons - categorical ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_imports.html"><b>6.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_flashback.html"><b>6.2</b> Flashback</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_chisq_test.html"><b>6.3</b> Chi squared test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_fisher_exact_text.html"><b>6.4</b> Fisher’s exact test</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_bigger_table.html"><b>6.5</b> Bigger table</a></li>
<li><a class="menu-level-2" href="./compare_categ_test_for_independence.html"><b>6.6</b> Test for independence</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises.html"><b>6.7</b> Exercises - Comparisons ..</a></li>
<li><a class="menu-level-2" href="./compare_categ_data_exercises_solutions.html"><b>6.8</b> Solutions - Comparisons ..</a></li>
<li><a class="menu-level-1" href="./association.html"><b>7</b> Association</a></li>
<li><a class="menu-level-2" href="./assoc_and_pred_data_imports.html"><b>7.1</b> Chapter imports</a></li>
<li><a class="menu-level-2" href="./association_lin_relation.html"><b>7.2</b> Linear relation</a></li>
<li><a class="menu-level-2" href="./assocociation_covariance.html"><b>7.3</b> Covariance</a></li>
<li><a class="menu-level-2" href="./assoc_and_pred_correlation.html"><b>7.4</b> Correlation</a></li>
<li><a class="menu-level-2" href="./association_corr_pitfalls.html"><b>7.5</b> Correlation Pitfalls</a></li>
<li><a class="menu-level-1" href="./appendix.html"><b></b> Appendix</a></li>
<li><a class="menu-level-1" href="./references.html"><b>8</b> References</a></li>
</div>
</aside>

<div class="books-content">
<h2 data-number="5.3" id="sec:compare_contin_data_two_samp_ttest"><span class="header-section-number">5.3</span> Two samples Student’s t-test</h2>
<p>Imagine a friend that studies biology told you that he conducted a research in order to write a dissertation and earn a <a href="https://en.wikipedia.org/wiki/Master_of_Science">master’s degree</a>. As part of the research he tested a new drug (drug X) on mice. He hopes the drug is capable to reduce the body weights of the animals. He asks you for a help with the data analysis. The results obtained by him are as follows</p>
<pre class="language-julia"><code>import CSV as Csv
import DataFrames as Dfs

# if you are in &#39;code_snippets&#39; folder, then use: &quot;./ch05/miceBwt.csv&quot;
# if you are in &#39;ch05&#39; folder, then use: &quot;./miceBwt.csv&quot;
miceBwt = Csv.read(&quot;./code_snippets/ch05/miceBwt.csv&quot;, Dfs.DataFrame)
first(miceBwt, 3)
</code></pre>
<div id="tbl:mBwtDf">
<table>
<caption>Table 1: Body mass [g] of mice (fictitious data).</caption>
<thead>
<tr class="header">
<th style="text-align: right;">noDrugX</th>
<th style="text-align: right;">drugX</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">26</td>
<td style="text-align: right;">26</td>
</tr>
<tr class="even">
<td style="text-align: right;">26</td>
<td style="text-align: right;">25</td>
</tr>
<tr class="odd">
<td style="text-align: right;">24</td>
<td style="text-align: right;">25</td>
</tr>
</tbody>
</table>
</div>
<p>Here, we opened a table with a made up data for mice body weight [g] (this dataset can be found <a href="https://github.com/b-lukaszuk/RJ_BS_eng/tree/main/code_snippets/ch05">here</a>). For that we used two new packages (<a href="https://csv.juliadata.org/stable/">CSV</a>, and <a href="https://dataframes.juliadata.org/stable/">DataFrames</a>).</p>
<p>A <code>*.csv</code> file can be opened and created, e.g. with a <a href="https://en.wikipedia.org/wiki/List_of_spreadsheet_software">spreadsheet</a> program. Here, we read it as a <code>DataFrame</code>, i.e. a structure that resembles an array from Section <a href="./julia_language_variables.html#sec:julia_arrays">3.3.7</a>. Since the <code>DataFrame</code> could potentially have thousands of rows we displayed only the first three (to check that everything succeeded) using <code>first</code> function.</p>
<blockquote>
<p><strong><em>Note:</em></strong> We can check the size of a <code>DataFrame</code> with <code>size</code> function which returns the information in a friendly <code>(numRows, numCols)</code> format.</p>
</blockquote>
<p>OK, let’s take a look at some descriptive statistics using <a href="https://dataframes.juliadata.org/stable/lib/functions/#DataAPI.describe">describe</a> function.</p>
<pre class="language-julia"><code>Dfs.describe(miceBwt)
</code></pre>
<div id="tbl:mBwtDescribe">
<table>
<caption>Table 2: Body mass of mice. Descriptive statistics.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">variable</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">median</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">nmissing</th>
<th style="text-align: right;">eltype</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">noDrugX</td>
<td style="text-align: right;">25.5</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">25.5</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">Int64</td>
</tr>
<tr class="even">
<td style="text-align: right;">drugX</td>
<td style="text-align: right;">24.1</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">24.5</td>
<td style="text-align: right;">26</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">Int64</td>
</tr>
</tbody>
</table>
</div>
<p>It appears that mice from group <code>drugX</code> got somewhat lower body weight. But that could be just a coincidence. Anyway, how should we analyze this data? Well, it depends on the experiment design.</p>
<p>Since we have 10 rows (<code>size(miceBwt)[1]</code>). Then, either:</p>
<ul>
<li>we had 10 mice at the beginning. The mice were numbered randomly 1:10 on their tails. Then we measured their initial weight (<code>noDrugX</code>), administered the drug and measured their body weight after, e.g. one week (<code>drugX</code>), or</li>
<li>we had 20 mice at the beginning. The mice were numbered randomly 1:20 on their tails. Then first 10 of them (numbers 1:10) became controls (regular food, group: <code>noDrugX</code>) and the other 10 (11:20) received additionally <code>drugX</code> (hence group <code>drugX</code>).</li>
</ul>
<p>Interestingly, the experimental models deserve slightly different statistical methodology. In the first case we will perform paired samples t-test, whereas in the other case we will use unpaired samples t-test. Ready, let’s go.</p>
<h3 data-number="5.3.1" id="sec:compare_contin_data_paired_ttest"><span class="header-section-number">5.3.1</span> Paired samples Student’s t-test</h3>
<p>Running a paired Student’s t-test with <code>HypothesisTests</code> package is very simple. We just have to send the specific column(s) to the appropriate function. Column selection can be done in one of the few ways, e.g. <code>miceBwt[:, "noDrugX"]</code> (similarly to array indexing in Section <a href="./julia_language_variables.html#sec:julia_arrays">3.3.7</a> <code>:</code> means all rows, note that this form copies the column), <code>miceBwt[!, "noDrugX"]</code> (<code>!</code> instead of <code>:</code>, no copying), <code>miceBwt.noDrugX</code> (again, no copying).</p>
<blockquote>
<p><strong><em>Note:</em></strong> Copying a column is advantageous when a function may modify the input data, but it is less effective for big data frames. If you wonder does a function changes its input then for starter look at its name and compare it with the convention we discussed in Section <a href="./julia_language_functions.html#sec:functions_modifying_arguments">3.4.4</a>. Still, to be sure you would have to examine the function’s code.</p>
</blockquote>
<p>And now we can finally run the paired t-test.</p>
<pre class="language-julia"><code># miceBwt.noDrugX or miceBwt.noDrugX returns a column as a Vector
Htests.OneSampleTTest(miceBwt.noDrugX, miceBwt.drugX)</code></pre>
<pre class="output"><code>One sample t-test
-----------------
Population details:
    parameter of interest:   Mean
    value under h_0:         0
    point estimate:          1.4
    95% confidence interval: (0.04271, 2.757)

Test summary:
    outcome with 95% confidence: reject h_0
    two-sided p-value:           0.0445

Details:
    number of observations:   10
    t-statistic:              2.3333333333333335
    degrees of freedom:       9
    empirical standard error: 0.6
</code></pre>
<p>And voila. We got the result. It seems that <code>drugX</code> actually does lower the body mass of the animals (p &lt; 0.05). But wait, didn’t we want to do a (paired) two-samples t-test and not <code>OneSampleTTest</code>? Yes, we did. Interestingly enough, a paired t-test is actually a one-sample t-test for the difference. Observe.</p>
<pre class="language-julia"><code># miceBwt.noDrugX or miceBwt.noDrugX returns a column as a Vector
# hence we can do elementwise subtraction using dot syntax
miceBwtDiff = miceBwt.noDrugX .- miceBwt.drugX
Htests.OneSampleTTest(miceBwtDiff)</code></pre>
<pre class="output"><code>One sample t-test
-----------------
Population details:
    parameter of interest:   Mean
    value under h_0:         0
    point estimate:          1.4
    95% confidence interval: (0.04271, 2.757)

Test summary:
    outcome with 95% confidence: reject h_0
    two-sided p-value:           0.0445

Details:
    number of observations:   10
    t-statistic:              2.3333333333333335
    degrees of freedom:       9
    empirical standard error: 0.6
</code></pre>
<p>Here, we used the familiar dot syntax from Section <a href="./julia_language_repetition.html#sec:julia_language_dot_functions">3.6.5</a> to obtain the differences and then fed the result to <code>OneSampleTTest</code> from the previous section (see Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a>). The output is the same as in the previous code snippet.</p>
<p>I don’t know about you, but when I was a student I often wondered when to choose paired and when unpaired t-test. Now I finally know, and it is so simple. Too bad that most statistical programs/packages separate paired t-test from one-sample t-test (unlike the authors of the <code>HypothesisTests</code> package).</p>
<p>Anyway, this also demonstrates an important feature of the data. The data points in both columns/groups need to be properly ordered, e.g. in our case it makes little sense to subtract body mass of a mouse with 1 on its tail from a mouse with 5 on its tail, right? Doing so has just as little sense as subtracting it from mouse number 6, 7, 8, etc. There is only one clearly good way to do this subtraction and this is to subtract mouse number 1 (<code>noDrugX</code>) from mouse number 1 (<code>drugX</code>). So, if you ever wonder paired or unpaired t-test then think if is there a clearly better way to subtract one column of data from the other. If so, then you should go with the paired t-test, otherwise choose the unpaired t-test.</p>
<p>BTW, do you remember how in Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_check_assump">5.2.2</a> we checked the assumptions of our <code>oneSampleTTest</code>, well it turns out that here we should do the same. However, this time instead of Kolmogorov-Smirnov test I’m going to use Shapiro-Wilk’s normality test from <code>Pingouin</code> package (Shapiro-Wilk is usually more powerful + the syntax and output of the function is nicer here).</p>
<pre class="language-julia"><code>import Pingouin as Pg
Pg.normality(miceBwtDiff)
</code></pre>
<div id="tbl:mBwtShapiro">
<table>
<caption>Table 3: Shapiro-Wilk’s normality test.</caption>
<thead>
<tr class="header">
<th style="text-align: right;">W</th>
<th style="text-align: right;">pval</th>
<th style="text-align: right;">normal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.9418099829866745</td>
<td style="text-align: right;">0.5733239948410133</td>
<td style="text-align: right;">1.0</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p><strong><em>Note:</em></strong> At the time I’m writing these words (29-08-2023) <a href="https://github.com/clementpoiret/Pingouin.jl">Pingouin</a> package is still under development. This may cause some inconveniences, warnings, etc. Proceed with caution.</p>
</blockquote>
<p>There, all normal (p &gt; 0.05). So, we were right to perform the test. Still, the order was incorrect, in general you should remember to check the assumptions first and then proceed with the test. In case the normality assumption did not hold we should consider doing a <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">Wilcoxon test</a> (non-parametric test), e.g. like so <code>Htests.SignedRankTest(df.noDrugX, df.drugX)</code> or <code>Htests.SignedRankTest(miceBwtDiff)</code>. More info on the test can be found in the link above or on the pages of <code>HypothesisTests</code> package (see <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Wilcoxon-signed-rank-test">here</a>).</p>
<h3 data-number="5.3.2" id="sec:compare_contin_data_unpaired_ttest"><span class="header-section-number">5.3.2</span> Unpaired samples Student’s t-test</h3>
<p>OK, now it’s time to move to the other experimental models. A reminder, here we discuss the following situation:</p>
<ul>
<li>we had 20 mice at the beginning. The mice were numbered randomly 1:20 on their tails. Then first 10 of them (numbers 1:10) became controls (regular food, group: <code>noDrugX</code>) and the other 10 (11:20) received additionally <code>drugX</code> (hence group <code>drugX</code>).</li>
</ul>
<p>Here we will compare mice <code>noDrugX</code> (miceID: 1:10) with mice <code>drugX</code> (miceID: 11:20) using unpaired samples t-test, but this time we will start by checking the assumptions.</p>
<p>First the normality assumption.</p>
<pre class="language-julia"><code># for brevity we will extract just the p-values
(
Pg.normality(miceBwt.noDrugX).pval,
Pg.normality(miceBwt.drugX).pval
)</code></pre>
<pre class="output"><code>([0.6833331724399375], [0.3254417851120679])</code></pre>
<p>OK, no reason to doubt the normality (p-vals &gt; 0.05). The other assumption that we may test is homogeneity of variance. Homogeneity means that the spread of data around the mean in each group is similar (sd(gr1) ≈ sd(gr2)). Here, we are going to use <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#Fligner-Killeen-test">Fligner-Killeen</a> test from the <code>HypothesisTests</code> package.</p>
<pre class="language-julia"><code>Htests.FlignerKilleenTest(miceBwt.noDrugX, miceBwt.drugX)</code></pre>
<pre class="output"><code>Fligner-Killeen test
--------------------
Population details:
    parameter of interest:   Variances
    value under h_0:         &quot;all equal&quot;
    point estimate:          NaN

Test summary:
    outcome with 95% confidence: fail to reject h_0
    p-value:                     1.0000

Details:
    number of observations: [10, 10]
    FK statistic:           4.76242e-31
    degrees of freedom:     1
</code></pre>
<p>Also this time, the assumption is fulfilled, and now for the unpaired test.</p>
<pre class="language-julia"><code>Htests.EqualVarianceTTest(
    miceBwt.noDrugX, miceBwt.drugX)</code></pre>
<pre class="output"><code>Two sample t-test (equal variance)
----------------------------------
Population details:
    parameter of interest:   Mean difference
    value under h_0:         0
    point estimate:          1.4
    95% confidence interval: (-0.1877, 2.988)

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.0804

Details:
    number of observations:   [10,10]
    t-statistic:              1.8525405838431677
    degrees of freedom:       18
    empirical standard error: 0.7557189365836423
</code></pre>
<p>It appears there is not enough evidence to reject the <span class="math inline">\(H_{0}\)</span> (the mean difference is equal to 0) on the cutoff level of 0.05. So, how could that be, the means in both groups are still the same, i.e. <code>Stats.mean(miceBwt.noDrugX)</code> = 25.5 and <code>Stats.mean(miceBwt.drugX)</code> = 24.1, yet we got different results (reject <span class="math inline">\(H_{0}\)</span> from paired t-test, not reject <span class="math inline">\(H_{0}\)</span> from unpaired t-test). Well, it is because we calculated slightly different things and because using paired samples usually removes some between subjects variability.</p>
<p>In the case of unpaired t-test we:</p>
<ol type="1">
<li>assume that the difference between the means under <span class="math inline">\(H_{0}\)</span> is equal to 0.</li>
<li>calculate the observed difference between the means, <code>Stats.mean(miceBwt.noDrugX) - Stats.mean(miceBwt.drugX)</code> = 1.4.</li>
<li>calculate the sem (with a slightly different formula than for the one-sample/paired t-test)</li>
<li>obtain the z-score (in case of t-test it is named t-score or t-statistics)</li>
<li>calculate the probability from t-test (slightly different calculation of the degrees of freedom)</li>
</ol>
<p>When compared with the methodology for one-sample t-test from Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a> it differs only with respect to the points 3, 4 and 5 above. Observe. First the functions</p>
<pre class="language-julia"><code>function getSem(v1::Vector{&lt;:Real}, v2::Vector{&lt;:Real})::Float64
    sem1::Float64 = getSem(v1)
    sem2::Float64 = getSem(v2)
    return sqrt((sem1^2) + (sem2^2))
end

function getDf(v1::Vector{&lt;:Real}, v2::Vector{&lt;:Real})::Int
    return getDf(v1) + getDf(v2)
end</code></pre>
<p>There are different formulas for pooled sem (standard error of the mean), but I only managed to remember this one because it reminded me the famous <a href="https://en.wikipedia.org/wiki/Pythagorean_theorem">Pythagorean theorem</a>, i.e. <span class="math inline">\(c^2 = a^2 + b^2\)</span>, so <span class="math inline">\(c = \sqrt{a^2 + b^2}\)</span>, that I learned in a primary school. As for the degrees of freedom they are just the sum of the degrees of freedom for each of the vectors. OK, so now the calculations</p>
<pre class="language-julia"><code>meanDiffBwtH0 = 0
meanDiffBwt = Stats.mean(miceBwt.noDrugX) - Stats.mean(miceBwt.drugX)
pooledSemBwt = getSem(miceBwt.noDrugX, miceBwt.drugX)
zScoreBwt = getZScore(meanDiffBwt, pooledSemBwt, meanDiffBwtH0)
dfBwt = getDf(miceBwt.noDrugX, miceBwt.drugX)
pValBwt = Dsts.cdf(Dsts.TDist(dfBwt), zScoreBwt) * 2</code></pre>
<p>And finally the result that you may compare with the output of the unpaired t-test above and the methodology for the one-sample t-test from Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a>.</p>
<pre class="language-julia"><code>(
meanDiffBwtH0, # value under h_0
round(meanDiffBwt, digits = 4), # point estimate
round(pooledSemBwt, digits = 4), # empirical standard error
# to get a positive zScore we should have calculated it as:
# getZScore(meanDiffBwtH0, pooledSemBwt, meanDiffBwt)
round(zScoreBwt, digits = 4), # t-statistic
dfBwt, # degrees of freedom
round(pValBwt, digits=4) # two-sided p-value
)</code></pre>
<pre class="output"><code>(0, 1.4, 0.7557, -1.8525, 18, 0.0804)</code></pre>
<p>Amazing. In the case of the unpaired two-sample t-test we use the same methodology and reasoning as we did in the case of the one-sample t-test from Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a> (only functions for <code>sem</code> and <code>df</code> changed slightly). Given the above I recommend you get back to the section Section <a href="./compare_contin_data_one_samp_ttest.html#sec:compare_contin_data_one_samp_ttest">5.2</a> and make sure you understand the explanations presented there (if you haven’t done this already).</p>
<p>As an alternative to our unpaired t-test we should consider <code>Htests.UnequalVarianceTTest</code> (if the variances are not equal) or <a href="https://juliastats.org/HypothesisTests.jl/stable/nonparametric/#HypothesisTests.MannWhitneyUTest">Htests.MannWhitneyUTest</a> (if both the normality and homogeneity assumptions do not hold).</p>


<div class="bottom-nav">
    <p id="nav-prev" style="text-align: left;">
        <a class="menu-level-2" href="./compare_contin_data_one_samp_ttest.html"><b>5.2</b> One sample Student’s t..</a> <kbd>←</kbd>
        <span id="nav-next" style="float: right;">
            <kbd>→</kbd> <a class="menu-level-2" href="./compare_contin_data_one_way_anova.html"><b>5.4</b> One-way ANOVA</a>
        </span>
    </p>
</div>


<div class="license">
    <br/>
  <br/>
  <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
    Bartlomiej Lukaszuk
</div>
</div>
</div>
</body>
</html>